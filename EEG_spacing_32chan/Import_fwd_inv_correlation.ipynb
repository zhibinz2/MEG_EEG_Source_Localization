{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "from hdf5storage import loadmat, savemat \n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse, compute_source_psd_epochs, write_inverse_operator\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Fs', 'ch_bad', 'ch_dubious', 'ch_labels', 'chanlocs', 'preprocessed_eeg', 'subject_ID'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdict=loadmat('preprocessed_eeg.mat')\n",
    "outdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_eeg=outdict['preprocessed_eeg']*0.000001 # reduce the amplitube to be shown on MNE's plot\n",
    "sampling_freq=outdict['Fs'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_eeg[1,1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=raw.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[1,1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_bad=[] # ch_bad=outdict['ch_bad'][0]-1\n",
    "ch_dubious=[] # ch_dubious=outdict['ch_dubious'][0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_ID=outdict['subject_ID'][0]\n",
    "\n",
    "n_channels=np.shape(preprocessed_eeg)[0]\n",
    "ch_info_bads=np.concatenate((ch_bad, ch_dubious), axis=0)\n",
    "ch_info_bads=np.unique(ch_info_bads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_labels=outdict['ch_labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_labels_names=list()\n",
    "for i in range(32):\n",
    "    ch_labels_names.append(ch_labels[i][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = [f\"E{n}\" for n in range(1, 33)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: E1, E2, E3, E4, E5, E6, E7, E8, E9, E10, E11, E12, E13, E14, ...\n",
      " chs: 32 EEG\n",
      " custom_ref_applied: False\n",
      " description: 20220713\n",
      " dig: 35 items (3 Cardinal, 32 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1000.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 32\n",
      " projs: []\n",
      " sfreq: 2000.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "ch_types = [\"eeg\"] * n_channels\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage(\"GSN-HydroCel-32\",match_case=False,match_alias=False,on_missing='raise', verbose=None)\n",
    "info[\"description\"] = subject_ID\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['chs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method \n",
    "# raw=mne.io.read_raw_fif('./TMSi32chan_loc_small_example.fif') # (this fif file is imported from original Poly5 to EDF to MNE)\n",
    "# missing dig in the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(info['dig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('./xyzlabels.mat') # (this xyzlabels.mat has coordinates from original Poly to EDF to MNE)\n",
    "x=outdict['x']\n",
    "y=outdict['y']\n",
    "z=outdict['z']\n",
    "\n",
    "# this set of xyz does not look right to work as digitaization points for coregistartion, but works for topoplot\n",
    "for ch in range(3,len(info['dig'])):\n",
    "    info['dig'][ch]['r'][0]=x[ch-3]\n",
    "    info['dig'][ch]['r'][1]=y[ch-3]\n",
    "    info['dig'][ch]['r'][2]=z[ch-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['dig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['chs'][0] # don't know why it is different from dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdict=loadmat('./xyzlabels.mat') # (this xyzlabels.mat has coordinates from original Poly to EDF to MNE)\n",
    "# x=outdict['x']\n",
    "# y=outdict['y']\n",
    "# z=outdict['z']\n",
    "\n",
    "for ch in range(32):\n",
    "    info['chs'][ch]['loc'][0]=x[ch]\n",
    "    info['chs'][ch]['loc'][1]=y[ch]\n",
    "    info['chs'][ch]['loc'][2]=z[ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['dig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['chs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('./xyzlabels.mat') # (this xyzlabels.mat has coordinates from original Poly to EDF to MNE)\n",
    "Coordinates=np.zeros((32,3))\n",
    "Coordinates[:,0]=outdict['x']\n",
    "Coordinates[:,1]=outdict['y']\n",
    "Coordinates[:,2]=outdict['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates=outdict['Coordianates']/1000\n",
    "# for ch in range(3,len(info['dig'])):\n",
    "#     info['dig'][ch]['r']=Coordinates[ch-3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark the bad channels\n",
    "ch_labels_info_bads=list()\n",
    "for k in range(len(ch_info_bads)):\n",
    "    ch_labels_info_bads.append(ch_names[ch_info_bads[k]])\n",
    "\n",
    "info['bads'] = ch_labels_info_bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=258122\n",
      "    Range : 0 ... 258121 =      0.000 ...   129.060 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>35 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>32 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>2000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Projections</th>\n",
       "        <td>Average EEG reference : off</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:02:10 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawArray | 32 x 258122 (129.1 s), ~63.1 MB, data loaded>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = mne.io.RawArray(preprocessed_eeg, info)\n",
    "raw.set_eeg_reference('average', projection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.plot(show_scrollbars=False, show_scalebars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/EEG_spacing_32chan/raw.fif\n",
      "Closing /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/EEG_spacing_32chan/raw.fif\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "raw.save(\"raw.fif\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.plot_alignment(\n",
    "#     raw.info)\n",
    "# mne.viz.set_3d_view(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topoplot\n",
    "# import numpy as np\n",
    "# x=np.random.rand(32)\n",
    "# x=list(x*100)\n",
    "# # x=list(range(1,33,1))\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(1)\n",
    "# mne.viz.plot_topomap(x, \\\n",
    "#     raw.info, vlim=(None, None), axes=ax,\\\n",
    "#         sensors=True, names=ch_labels_names, cmap='seismic')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.gui.coregistration()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the source space with the following parameters:\n",
      "\n",
      "SUBJECTS_DIR = /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/EEG_spacing_32chan/../../archive/subjects\n",
      "Subject      = fsaverage\n",
      "Surface      = white\n",
      "Icosahedron subdivision grade 4\n",
      "\n",
      ">>> 1. Creating the source space...\n",
      "\n",
      "Doing the icosahedral vertex picking...\n",
      "Loading /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/EEG_spacing_32chan/../../archive/subjects/fsaverage/surf/lh.white...\n",
      "Mapping lh fsaverage -> ico (4) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/EEG_spacing_32chan/../../archive/subjects/fsaverage/surf/lh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded lh.white 2562/163842 selected to source space (ico = 4)\n",
      "\n",
      "Loading /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/EEG_spacing_32chan/../../archive/subjects/fsaverage/surf/rh.white...\n",
      "Mapping rh fsaverage -> ico (4) ...\n",
      "    Warning: zero size triangles: [3 4]\n",
      "    Triangle neighbors and vertex normals...\n",
      "Loading geometry from /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/EEG_spacing_32chan/../../archive/subjects/fsaverage/surf/rh.sphere...\n",
      "Setting up the triangulation for the decimated surface...\n",
      "loaded rh.white 2562/163842 selected to source space (ico = 4)\n",
      "\n",
      "Calculating patch information (limit=0.0 mm)...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "You are now one step closer to computing the gain matrix\n",
      "Creating the BEM geometry...\n",
      "Going from 5th to 4th subdivision of an icosahedron (n_tri: 20480 -> 5120)\n",
      "Going from 5th to 4th subdivision of an icosahedron (n_tri: 20480 -> 5120)\n",
      "Going from 5th to 4th subdivision of an icosahedron (n_tri: 20480 -> 5120)\n",
      "outer skin  CM is  -0.21 -19.38  -0.23 mm\n",
      "outer skull CM is  -0.19 -19.34  -0.49 mm\n",
      "inner skull CM is  -0.53 -21.10   6.21 mm\n",
      "Checking that surface outer skull is inside surface outer skin  ...\n",
      "Checking that surface inner skull is inside surface outer skull ...\n",
      "Checking distance between outer skin  and outer skull surfaces...\n",
      "Minimum distance between the outer skin  and outer skull surfaces is approximately    1.6 mm\n",
      "Checking distance between outer skull and inner skull surfaces...\n",
      "Minimum distance between the outer skull and inner skull surfaces is approximately    5.4 mm\n",
      "Surfaces passed the basic topology checks.\n",
      "Complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the raw file containing the channel location + types\n",
    "raw_fname = './raw.fif'\n",
    "\n",
    "# The paths to Freesurfer reconstructions\n",
    "subjects_dir ='../../archive/subjects/'\n",
    "subject = 'fsaverage' # change it to use freesurfer's bem\n",
    "\n",
    "# Compute Source Space (surface)\n",
    "ico = 4 #**************************************************************\n",
    "spacing='ico'+str(ico) \n",
    "src = mne.setup_source_space(subject, spacing=spacing, add_dist='patch',\n",
    "                             subjects_dir=subjects_dir)\n",
    "conductivity = (0.3, 0.0075, 0.3)  #  three layers for EEG (MNE default  (0.3 0.006 0.3) )\n",
    "model = mne.make_bem_model(subject=subject, ico=ico,\n",
    "                           conductivity=conductivity,\n",
    "                           subjects_dir=subjects_dir)\n",
    "# 5 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three-layer model surfaces loaded.\n",
      "Computing the linear collocation solution...\n",
      "    Matrix coefficients...\n",
      "        outer skin  (2562) -> outer skin  (2562) ...\n",
      "        outer skin  (2562) -> outer skull (2562) ...\n",
      "        outer skin  (2562) -> inner skull (2562) ...\n",
      "        outer skull (2562) -> outer skin  (2562) ...\n",
      "        outer skull (2562) -> outer skull (2562) ...\n",
      "        outer skull (2562) -> inner skull (2562) ...\n",
      "        inner skull (2562) -> outer skin  (2562) ...\n",
      "        inner skull (2562) -> outer skull (2562) ...\n",
      "        inner skull (2562) -> inner skull (2562) ...\n",
      "    Inverting the coefficient matrix...\n",
      "IP approach required...\n",
      "    Matrix coefficients (homog)...\n",
      "        inner skull (2562) -> inner skull (2562) ...\n",
      "    Inverting the coefficient matrix (homog)...\n",
      "    Modify the original solution to incorporate IP approach...\n",
      "        Combining...\n",
      "        Scaling...\n",
      "Solution ready.\n",
      "BEM geometry computations complete.\n"
     ]
    }
   ],
   "source": [
    "bem = mne.make_bem_solution(model)\n",
    "\n",
    "trans = './tmsi_trans.fif'\n",
    "# 1m 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view surfaces\n",
    "# plot_bem_kwargs = dict(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     brain_surfaces=\"white\",\n",
    "#     orientation=\"coronal\",\n",
    "#     slices=[50, 100, 150, 200],\n",
    "# )\n",
    "\n",
    "# mne.viz.plot_bem(**plot_bem_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualing the coregistration \n",
    "# info = mne.io.read_info(raw_fname)\n",
    "# # Here we look at the dense head, which isn't used for BEM computations but\n",
    "# # is useful for coregistration.\n",
    "# mne.viz.plot_alignment(\n",
    "#     info,\n",
    "#     trans,\n",
    "#     subject=subject,\n",
    "#     dig=True,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     surfaces=\"pial\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.viz.plot_bem(src=src, **plot_bem_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface = '../../archive/subjects/fsaverage/bem/inner_skull.surf'\n",
    "# vol_src = mne.setup_volume_source_space(\n",
    "#     subject, subjects_dir=subjects_dir, surface=surface, add_interpolator=False\n",
    "# )  # Just for speed!\n",
    "# print(vol_src)\n",
    "\n",
    "# mne.viz.plot_bem(src=vol_src, **plot_bem_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"mri\",\n",
    "#     src=src,\n",
    "# )\n",
    "# mne.viz.set_3d_view(\n",
    "#     fig,\n",
    "#     azimuth=173.78,\n",
    "#     elevation=101.75,\n",
    "#     distance=0.30,\n",
    "#     focalpoint=(-0.03, -0.01, 0.03),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space          : <SourceSpaces: [<surface (lh), n_vertices=163842, n_used=2562>, <surface (rh), n_vertices=163842, n_used=2562>] MRI (surface RAS) coords, subject 'fsaverage', ~30.8 MB>\n",
      "MRI -> head transform : ./tmsi_trans.fif\n",
      "Measurement data      : raw.fif\n",
      "Conductor model   : instance of ConductorModel\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Read 2 source spaces a total of 5124 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     0.999231 -0.035340  0.017012      -2.10 mm\n",
      "     0.036517  0.996533 -0.074755      12.96 mm\n",
      "    -0.014311  0.075319  0.997057      -2.61 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read  32 EEG channels from info\n",
      "Head coordinate coil definitions created.\n",
      "Source spaces are now in head coordinates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model instance of ConductorModel is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n",
      "Checking surface interior status for 2562 points...\n",
      "    Found  609/2562 points inside  an interior sphere of radius   47.7 mm\n",
      "    Found    0/2562 points outside an exterior sphere of radius   98.3 mm\n",
      "    Found    0/1953 points outside using surface Qhull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found    0/1953 points outside using solid angles\n",
      "    Total 2562/2562 points inside the surface\n",
      "Interior check completed in 6755.6 ms\n",
      "Checking surface interior status for 2562 points...\n",
      "    Found  561/2562 points inside  an interior sphere of radius   47.7 mm\n",
      "    Found    0/2562 points outside an exterior sphere of radius   98.3 mm\n",
      "    Found    0/2001 points outside using surface Qhull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found    0/2001 points outside using solid angles\n",
      "    Total 2562/2562 points inside the surface\n",
      "Interior check completed in 475.7 ms\n",
      "\n",
      "Setting up for EEG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing EEG at 5124 source locations (free orientations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished.\n",
      "<Forward | MEG channels: 0 | EEG channels: 32 | Source space: Surface with 5124 vertices | Source orientation: Free>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "fwd = mne.make_forward_solution(raw_fname, trans=trans, src=src, bem=bem,\n",
    "                                meg=False, eeg=True, mindist=5.0, n_jobs=2,\n",
    "                                verbose=True)\n",
    "print(fwd)\n",
    "\n",
    "# 10s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lh = fwd[\"src\"][0]  # Visualize the left hemisphere\n",
    "# verts = lh[\"rr\"]  # The vertices of the source space\n",
    "# tris = lh[\"tris\"]  # Groups of three vertices that form triangles\n",
    "# dip_pos = lh[\"rr\"][lh[\"vertno\"]]  # The position of the dipoles\n",
    "# dip_ori = lh[\"nn\"][lh[\"vertno\"]]\n",
    "# dip_len = len(dip_pos)\n",
    "# dip_times = [0]\n",
    "# white = (1.0, 1.0, 1.0)  # RGB values for a white color\n",
    "\n",
    "# actual_amp = np.ones(dip_len)  # misc amp to create Dipole instance\n",
    "# actual_gof = np.ones(dip_len)  # misc GOF to create Dipole instance\n",
    "# dipoles = mne.Dipole(dip_times, dip_pos, actual_amp, dip_ori, actual_gof)\n",
    "# trans = mne.read_trans('tmsi_trans.fif')\n",
    "\n",
    "# fig = mne.viz.create_3d_figure(size=(600, 400), bgcolor=white)\n",
    "# coord_frame = \"mri\"\n",
    "\n",
    "# # Plot the cortex\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=coord_frame,\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# # Mark the position of the dipoles with small red dots\n",
    "# mne.viz.plot_dipole_locations(\n",
    "#     dipoles=dipoles,\n",
    "#     trans=trans,\n",
    "#     mode=\"sphere\",\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     coord_frame=coord_frame,\n",
    "#     scale=7e-4,\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# mne.viz.set_3d_view(figure=fig, azimuth=180, distance=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.create_3d_figure(size=(600, 400))\n",
    "\n",
    "# # Plot the cortex\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"head\",\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# # Show the three dipoles defined at each location in the source space\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     fwd=fwd,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"head\",\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# mne.viz.set_3d_view(figure=fig, azimuth=180, distance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.create_3d_figure(size=(600, 400))\n",
    "\n",
    "# # Plot the cortex\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"head\",\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# # Show the dipoles as arrows pointing along the surface normal\n",
    "# mne.viz.plot_dipole_locations(\n",
    "#     dipoles=dipoles,\n",
    "#     trans=trans,\n",
    "#     mode=\"arrow\",\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     coord_frame=\"head\",\n",
    "#     scale=7e-4,\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# mne.viz.set_3d_view(figure=fig, azimuth=180, distance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Leadfield size : 32 sensors x 5124 dipoles\n"
     ]
    }
   ],
   "source": [
    "fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                         use_cps=True)\n",
    "leadfield = fwd_fixed['sol']['data']\n",
    "source_rr=fwd_fixed['source_rr']\n",
    "print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_332729/1225453021.py:1: RuntimeWarning: This filename (fwd.fif) does not conform to MNE naming conventions. All forward files should end with -fwd.fif, -fwd.fif.gz, _fwd.fif or _fwd.fif.gz\n",
      "  mne.write_forward_solution('fwd.fif', fwd_fixed, overwrite=True, verbose=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Write a source space...\n",
      "    [done]\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    2 source spaces written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_332729/1225453021.py:1: RuntimeWarning: This forward solution is based on a forward solution with free orientation. The original forward solution is stored on disk in X/Y/Z RAS coordinates. Any transformation (surface orientation or fixed orientation) will be reverted. To reapply any transformation to the forward operator please apply convert_forward_solution after reading the forward solution with read_forward_solution.\n",
      "  mne.write_forward_solution('fwd.fif', fwd_fixed, overwrite=True, verbose=None)\n"
     ]
    }
   ],
   "source": [
    "mne.write_forward_solution('fwd.fif', fwd_fixed, overwrite=True, verbose=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw=mne.io.read_raw_fif(raw_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 645 segments\n",
      "Number of samples used : 258000\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "data_cov=mne.compute_raw_covariance(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 645 segments\n",
      "Number of samples used : 258000\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# # use the entire data as empty room noise\n",
    "# noise_cov = mne.compute_raw_covariance(raw)\n",
    "# noise_cov_mat=noise_cov['data'] # it only included the good chans\n",
    "# # compute the average of the diagonal\n",
    "# # construct the scale of the noise cov\n",
    "# # scale=0.05 # 1% 5% 10% 30% 50% *******************************************************************************\n",
    "# scale_ave=np.sqrt(np.mean(noise_cov_mat.diagonal()))*scale\n",
    "# sim_cov_mat=np.zeros((np.shape(noise_cov_mat)))\n",
    "# for i in range(np.shape(sim_cov_mat)[0]):\n",
    "#        sim_cov_mat[i,i]=scale_ave\n",
    "# sim_cov=noise_cov.copy()\n",
    "# sim_cov['data']=sim_cov_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 1 segment\n",
      "Using data from preloaded Raw for 1 events and 400 original time points ...\n",
      "0 bad epochs dropped\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.8e-12 (2.2e-16 eps * 32 dim * 2.5e+02  max singular value)\n",
      "    Estimated rank (eeg): 27\n",
      "    EEG: rank 27 computed from 32 data channels with 1 projector\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 32 -> 27\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using DIAGONAL_FIXED\n",
      "    EEG regularization : 0.1\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "    EEG regularization : 0.1\n",
      "    EEG regularization : 0.1\n",
      "    EEG regularization : 0.1\n",
      "Number of samples used : 400\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -64.301\n",
      "   diagonal_fixed: -65.059\n",
      "   empirical: -6531023010.936\n",
      "selecting best estimator: shrunk\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# sim_cov = mne.compute_raw_covariance(raw, tmin=10, tmax=20, method=\"shrunk\", method_params='pca', cv=3, rank=None)\n",
    "# sim_cov = mne.compute_raw_covariance(raw, tmin=10, tmax=10.2, method=\"auto\")\n",
    "# sim_cov_mat=sim_cov['data']\n",
    "\n",
    "#The method used for covariance estimation. If ‘empirical’ (default), the sample covariance will be computed. A list can be passed to perform estimates using multiple methods. If ‘auto’ or a list of methods, the best estimator will be determined based on log-likelihood and cross-validation on unseen data as described in 1. Valid methods are ‘empirical’, ‘diagonal_fixed’, ‘shrunk’, ‘oas’, ‘ledoit_wolf’, ‘factor_analysis’, ‘shrinkage’, and ‘pca’ (see Notes). If 'auto', it expands to:\n",
    "# ['shrunk', 'diagonal_fixed', 'empirical', 'factor_analysis']\n",
    "# 'factor_analysis' is removed when rank is not ‘full’. The 'auto' mode is not recommended if there are many segments of data, since computation can take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_cov_mat.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(noise_cov_mat,vmin=-1.5e-10, vmax=1.5e-10, cmap='jet')\n",
    "# plt.colorbar()\n",
    "# np.mean(noise_cov_mat.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.write_cov('noise_cov.fif', noise_cov, overwrite=True, verbose=None)\n",
    "# mne.write_cov('sim_cov.fif', sim_cov, overwrite=True, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nepochs=int(np.floor(np.shape(preprocessed_eeg)[1]/sampling_freq))\n",
    "# epochs_mat = np.column_stack(\n",
    "#     (\n",
    "#         np.arange(0, np.shape(preprocessed_eeg)[1]-sampling_freq, sampling_freq),\n",
    "#         np.zeros(nepochs, dtype=int),\n",
    "#         np.array([1]*nepochs),\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epoch_dict = dict(resting=1)\n",
    "# epochs = mne.Epochs(raw, epochs_mat, tmin=0, tmax=0.999, event_id=epoch_dict, preload=True, baseline=(None, None))\n",
    "\n",
    "# evoked = epochs[\"resting\"].average()\n",
    "# mne.write_evokeds('resting_ave.fif', evoked, on_mismatch='raise', overwrite=True, verbose=None)\n",
    "# evokeds = mne.read_evokeds('./resting_ave.fif')\n",
    "# resting = evokeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n"
     ]
    }
   ],
   "source": [
    "# fwd = mne.read_forward_solution('fwd.fif')\n",
    "fwd_surf=mne.convert_forward_solution(fwd, surf_ori=True, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse operator with 32 channels.\n",
      "    32 out of 32 channels remain after picking\n",
      "Selected 32 channels\n",
      "Creating the depth weighting matrix...\n",
      "    32 EEG channels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    limit = 5125/5124 = 3.100642\n",
      "    scale = 58980.7 exp = 0.8\n",
      "    Picked elements from a free-orientation depth-weighting prior into the fixed-orientation one\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 9.6e-15 (2.2e-16 eps * 32 dim * 1.4  max singular value)\n",
      "    Estimated rank (eeg): 27\n",
      "    EEG: rank 27 computed from 32 data channels with 1 projector\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 3.05961\n",
      "    scaling factor to adjust the trace = 3.52746e+19 (nchan = 32 nzero = 5)\n"
     ]
    }
   ],
   "source": [
    "# Compute the source estimate (Fixed dipole orientations)\n",
    "depth=0.8 # 0.8 1 2 4 ***************************************************************************************\n",
    "# inverse_operator = make_inverse_operator(resting.info, fwd, sim_cov, depth=depth, fixed=True)\n",
    "inverse_operator = make_inverse_operator(raw.info, fwd_surf, sim_cov, depth=depth, fixed=True)\n",
    "# save the inverse operator and the inverse matrix\n",
    "# write_inverse_operator('inv.fif', inverse_operator,overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linearly constrained minimum variance (LCMV) beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mne.beamformer import make_lcmv, apply_lcmv, apply_lcmv_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.4e-14 (2.2e-16 eps * 32 dim * 3.3  max singular value)\n",
      "    Estimated rank (eeg): 27\n",
      "    EEG: rank 27 computed from 32 data channels with 1 projector\n",
      "Computing rank from covariance with rank=None\n",
      "    EEG: rank 31 computed from 32 data channels with 1 projector\n",
      "Making LCMV beamformer with rank {'eeg': 27}\n",
      "Computing inverse operator with 32 channels.\n",
      "    32 out of 32 channels remain after picking\n",
      "Selected 32 channels\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "Computing rank from covariance with rank={'eeg': 27}\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing beamformer filters for 5124 sources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter computation complete\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "filters = make_lcmv(\n",
    "    raw.info,\n",
    "    fwd,\n",
    "    data_cov,\n",
    "    reg=0.05,\n",
    "    noise_cov=None,\n",
    "    pick_ori=\"max-power\",\n",
    "    weight_norm=\"unit-noise-gain\",\n",
    "    rank=None,\n",
    ")\n",
    "\n",
    "# # You can save the filter for later use with:\n",
    "# # filters.save('filters-lcmv.h5')\n",
    "\n",
    "# # stc = apply_lcmv(evoked, filters)\n",
    "# stc = apply_lcmv_raw(raw,filters) \n",
    "# # 32s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5124, 258122)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.shape(stc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters_vec = make_lcmv(\n",
    "#     evoked.info,\n",
    "#     fwd,\n",
    "#     noise_cov,\n",
    "#     reg=0.05,\n",
    "#     noise_cov=sim_cov,\n",
    "#     pick_ori=\"vector\",\n",
    "#     weight_norm=\"unit-noise-gain-invariant\",\n",
    "#     rank=None,\n",
    "# )\n",
    "# # save a bit of memory\n",
    "# # src = fwd_fixed[\"src\"]\n",
    "# # del fwd_fixed\n",
    "# stc_vec = apply_lcmv(evoked, filters_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run extract_invmat.ipynb # run this script to load the functions needed to extract inverse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 27 (5 small eigenvalues omitted)\n",
      "Applying inverse operator to \"\"...\n",
      "    Picked 32 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  78.6% variance\n",
      "[done]\n",
      "Dimension of Inverse Matrix: (5124, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5124, 32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = ['MNE','dSPM','sLORETA','eLORETA'] # **********************************************\n",
    "method = methods[0]  # (could also be dSPM or sLORETA)# **********************************************\n",
    "# invmat=_get_matrix_from_inverse_operator(inverse_operator,fwd,method=method,lambda2=1.0/9.0)\n",
    "# invmat=_get_matrix_from_inverse_operator(inverse_operator,fwd_fixed,method=method,lambda2=1.0/9.0)\n",
    "invmat=_get_matrix_from_inverse_operator(inverse_operator,fwd_surf,method=method,lambda2=1.0/9.0)\n",
    "np.shape(invmat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not ch_info_bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_332729/1154960953.py:2: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if ch_info_bads:\n"
     ]
    }
   ],
   "source": [
    "# remove bad channels from the original eeg\n",
    "if ch_info_bads:\n",
    "    original_eeg=np.delete(preprocessed_eeg,ch_info_bads,0)\n",
    "else:\n",
    "    original_eeg=preprocessed_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct eeg using invmat and leadfield matrix\n",
    "source_data=np.matmul(invmat,original_eeg)\n",
    "EEG_recon=np.matmul(leadfield,source_data)\n",
    "# 11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_332729/2141909429.py:2: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if ch_info_bads:\n"
     ]
    }
   ],
   "source": [
    "# remove bad channels from the reconstructed eeg\n",
    "if ch_info_bads:\n",
    "    EEG_recon=np.delete(EEG_recon,ch_info_bads,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0,np.shape(EEG_recon)[1],1),EEG_recon.transpose())\n",
    "# plt.title('reconstructed EEG - all chan')\n",
    "# plt.ylim([-2e-5,2e-5])\n",
    "# # 16 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0,np.shape(EEG_recon)[1],1),EEG_recon[ch_dubious,:].transpose())\n",
    "# plt.title('reconstructed EEG - dubious chan')\n",
    "# plt.ylim([-2e-5,2e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0,np.shape(EEG_recon)[1],1),EEG_recon[ch_bad,:].transpose())\n",
    "# plt.title('reconstructed EEG - bad chan')\n",
    "# plt.ylim([-2e-5,2e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation\n",
    "corr = np.corrcoef(EEG_recon, original_eeg, rowvar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # examine \n",
    "# chan=22 # 12, 30\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(np.arange(np.size(original_eeg,1)),original_eeg[chan,:],'r')\n",
    "# plt.title('original_eeg')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(np.arange(np.size(EEG_recon,1)),EEG_recon[chan,:],'b')\n",
    "# plt.title('reconstructed eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # examine\n",
    "# chan=31 # 12, 30\n",
    "# nsamples=2000\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(np.arange(nsamples),original_eeg[chan,10000:10000+nsamples],'r')\n",
    "# plt.title('original_eeg')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(np.arange(nsamples),EEG_recon[chan,10000:10000+nsamples],'b')\n",
    "# plt.title('reconstructed eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(0,np.shape(EEG_recon)[0],1)+194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr=corr[np.arange(0,np.shape(EEG_recon)[0],1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr=corr[:,np.arange(194,388,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(corr,cmap='jet',vmin=-1,vmax=1)\n",
    "# plt.ylabel('reconstructed EEG (194 good channels)')\n",
    "# plt.xlabel('original EEG (194 good channels)')\n",
    "# plt.title('correlation')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(corr,cmap='jet',vmin=-1,vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.title('corrceof: ico' + str(ico) + ' scale ' +str(scale) +' depth '+ str(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrcoef_diag=np.zeros((np.shape(EEG_recon)[0]))\n",
    "for i in range(np.shape(EEG_recon)[0]):\n",
    "    corrcoef_diag[i]=corr[i,np.shape(EEG_recon)[0]+i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50366832, 0.65748695, 0.6668578 , 0.81230012, 0.66848123,\n",
       "       0.47154086, 0.32322859, 0.88273558, 0.68596595, 0.65313332,\n",
       "       0.57246388, 0.42817665, 0.32466348, 0.70189323, 0.58176001,\n",
       "       0.47662543, 0.68849853, 0.08595481, 0.61839969, 0.57180669,\n",
       "       0.56618287, 0.81467732, 0.68074177, 0.35445782, 0.65668267,\n",
       "       0.43513664, 0.85775182, 0.68688725, 0.45541768, 0.6369609 ,\n",
       "       0.31715131, 0.95139205])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrcoef_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0, np.shape(EEG_recon)[0],1) ,corrcoef_diag, 'r.')\n",
    "# plt.title('corrceof: ico' + str(ico) + ' scale ' +str(scale) +' depth '+ str(depth))\n",
    "# plt.xlabel('good channels')\n",
    "# plt.ylabel('corrcoef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrcoef_diag # chan 13 (M1) and chan 31(OZ) have lowest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save outputs all in one mat file. \n",
    "# outdict=dict()\n",
    "# outdict['leadfield']=leadfield # leadfield matrix\n",
    "# outdict['invmat']=invmat #  inverse matrix\n",
    "# outdict['source_rr']=source_rr # the source location AND labels (matlab)\n",
    "# outdict['sim_cov_mat']=sim_cov_mat # noise covariance\n",
    "# outdict['scale']=scale # scale\n",
    "# outdict['depth']=depth # depth\n",
    "# outdict['conductivity']=conductivity # 3 layrs conductivity\n",
    "\n",
    "\n",
    "# outdict['ch_bad']=ch_bad #  inverse matrix\n",
    "# outdict['ch_dubious']=ch_dubious # \n",
    "# outdict['ch_names']=ch_names #  \n",
    "# outdict['Coordinates']=Coordinates #  \n",
    "# outdict['corrcoef_diag']=corrcoef_diag #  \n",
    "# outdict['subject_ID']=subject_ID #  \n",
    "\n",
    "# savemat(subject_ID+'_scale_'+str(scale)+'_depth_'+str(depth),outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdict=dict()\n",
    "# outdict['leadfield']=leadfield # leadfield matrix\n",
    "# outdict['invmat']=invmat #  inverse matrix\n",
    "# outdict['source_rr']=source_rr # the source location AND labels (matlab)\n",
    "# outdict['sim_cov_mat']=sim_cov_mat # noise covariance\n",
    "# # stc_data=stc.data\n",
    "# # outdict['stc']=stc_data # the source estimate\n",
    "# outdict['scale']='auto' # scale\n",
    "# outdict['depth']=depth # depth\n",
    "# outdict['conductivity']=conductivity # 3 layrs conductivity\n",
    "# outdict['ch_bad']=ch_bad #  inverse matrix\n",
    "# outdict['ch_dubious']=ch_dubious # \n",
    "# outdict['ch_names']=ch_names #  \n",
    "# outdict['Coordinates']=Coordinates #  \n",
    "# outdict['corrcoef_diag']=corrcoef_diag #  \n",
    "# outdict['subject_ID']=subject_ID #  \n",
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+'auto'+'_depth_'+str(depth),outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdict=dict()\n",
    "# outdict['leadfield']=leadfield # leadfield matrix\n",
    "# outdict['invmat']=invmat #  inverse matrix\n",
    "# outdict['source_rr']=source_rr # the source location AND labels (matlab)\n",
    "# outdict['sim_cov_mat']=sim_cov_mat # noise covariance\n",
    "# # stc_data=stc.data\n",
    "# # outdict['stc']=stc_data # the source estimate\n",
    "# outdict['scale']=scale # scale\n",
    "# outdict['depth']=depth # depth\n",
    "# outdict['conductivity']=conductivity # 3 layrs conductivity\n",
    "# outdict['ch_bad']=ch_bad #  inverse matrix\n",
    "# outdict['ch_dubious']=ch_dubious # \n",
    "# outdict['ch_names']=ch_names #  \n",
    "# outdict['Coordinates']=Coordinates #  \n",
    "# outdict['corrcoef_diag']=corrcoef_diag #  \n",
    "# outdict['subject_ID']=subject_ID #  \n",
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth),outdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(stc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # outdict=dict()\n",
    "# stc_data=stc.data\n",
    "# stc_data1=stc_data[0:1000,:]\n",
    "# stc_data2=stc_data[1000:2000,:]\n",
    "# stc_data3=stc_data[2000:3000,:]\n",
    "# stc_data4=stc_data[3000:4000,:]\n",
    "# stc_data5=stc_data[4000::,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stc.save(\"stc.fif\",overwrite=True, ftype='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdict['stc_data']=stc_data # the source estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# scipy.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy==1.11.3\n",
    "# the previous version is 1.9 compatible with sklearn 1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.io.savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data',\n",
    "#                  outdict,oned_as='column',format='5',do_compression=True)\n",
    "# # 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# filename = subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data'\n",
    "# fileObject = open(filename, 'wb')\n",
    "# pkl.dump(stc_data, fileObject)\n",
    "# fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hdf5storage\n",
    "# hdf5storage.__version__\n",
    "# # it was 0.1.18 previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hdf5storage==0.1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data.mat',\n",
    "#         outdict,do_compression=True,format='7.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data1.mat',\n",
    "#         {\"stc_data1\": stc_data1},do_compression=True,format='7.3')\n",
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data2.mat',\n",
    "#         {\"stc_data2\": stc_data2},do_compression=True,format='7.3')\n",
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data3.mat',\n",
    "#         {\"stc_data3\": stc_data3},do_compression=True,format='7.3')\n",
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data4.mat',\n",
    "#         {\"stc_data4\": stc_data4},do_compression=True,format='7.3')\n",
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data5.mat',\n",
    "#         {\"stc_data5\": stc_data5},do_compression=True,format='7.3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
