{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "from hdf5storage import loadmat, savemat \n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse, compute_source_psd_epochs, write_inverse_operator\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('preprocessed_eeg.mat')\n",
    "outdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_eeg=outdict['preprocessed_eeg']*0.000001 # reduce the amplitube to be shown on MNE's plot\n",
    "sampling_freq=outdict['Fs'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_eeg[1,1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=raw.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[1,1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_bad=[] # ch_bad=outdict['ch_bad'][0]-1\n",
    "ch_dubious=[] # ch_dubious=outdict['ch_dubious'][0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_ID=outdict['subject_ID'][0]\n",
    "\n",
    "n_channels=np.shape(preprocessed_eeg)[0]\n",
    "ch_info_bads=np.concatenate((ch_bad, ch_dubious), axis=0)\n",
    "ch_info_bads=np.unique(ch_info_bads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_labels=outdict['ch_labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_labels_names=list()\n",
    "for i in range(32):\n",
    "    ch_labels_names.append(ch_labels[i][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = [f\"E{n}\" for n in range(1, 33)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_types = [\"eeg\"] * n_channels\n",
    "info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "info.set_montage(\"GSN-HydroCel-32\",match_case=False,match_alias=False,on_missing='raise', verbose=None)\n",
    "info[\"description\"] = subject_ID\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['chs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method \n",
    "# raw=mne.io.read_raw_fif('./TMSi32chan_loc_small_example.fif') # (this fif file is imported from original Poly5 to EDF to MNE)\n",
    "# missing dig in the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(info['dig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('./xyzlabels.mat') # (this xyzlabels.mat has coordinates from original Poly to EDF to MNE)\n",
    "x=outdict['x']\n",
    "y=outdict['y']\n",
    "z=outdict['z']\n",
    "\n",
    "# this set of xyz does not look right to work as digitaization points for coregistartion, but works for topoplot\n",
    "for ch in range(3,len(info['dig'])):\n",
    "    info['dig'][ch]['r'][0]=x[ch-3]\n",
    "    info['dig'][ch]['r'][1]=y[ch-3]\n",
    "    info['dig'][ch]['r'][2]=z[ch-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['dig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['chs'][0] # don't know why it is different from dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdict=loadmat('./xyzlabels.mat') # (this xyzlabels.mat has coordinates from original Poly to EDF to MNE)\n",
    "# x=outdict['x']\n",
    "# y=outdict['y']\n",
    "# z=outdict['z']\n",
    "\n",
    "for ch in range(32):\n",
    "    info['chs'][ch]['loc'][0]=x[ch]\n",
    "    info['chs'][ch]['loc'][1]=y[ch]\n",
    "    info['chs'][ch]['loc'][2]=z[ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['dig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info['chs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=loadmat('./xyzlabels.mat') # (this xyzlabels.mat has coordinates from original Poly to EDF to MNE)\n",
    "Coordinates=np.zeros((32,3))\n",
    "Coordinates[:,0]=outdict['x']\n",
    "Coordinates[:,1]=outdict['y']\n",
    "Coordinates[:,2]=outdict['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates=outdict['Coordianates']/1000\n",
    "# for ch in range(3,len(info['dig'])):\n",
    "#     info['dig'][ch]['r']=Coordinates[ch-3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark the bad channels\n",
    "ch_labels_info_bads=list()\n",
    "for k in range(len(ch_info_bads)):\n",
    "    ch_labels_info_bads.append(ch_names[ch_info_bads[k]])\n",
    "\n",
    "info['bads'] = ch_labels_info_bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.RawArray(preprocessed_eeg, info)\n",
    "raw.set_eeg_reference('average', projection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.plot(show_scrollbars=False, show_scalebars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.save(\"raw.fif\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.plot_alignment(\n",
    "#     raw.info)\n",
    "# mne.viz.set_3d_view(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topoplot\n",
    "# import numpy as np\n",
    "# x=np.random.rand(32)\n",
    "# x=list(x*100)\n",
    "# # x=list(range(1,33,1))\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(1)\n",
    "# mne.viz.plot_topomap(x, \\\n",
    "#     raw.info, vlim=(None, None), axes=ax,\\\n",
    "#         sensors=True, names=ch_labels_names, cmap='seismic')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.gui.coregistration()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the raw file containing the channel location + types\n",
    "raw_fname = './raw.fif'\n",
    "\n",
    "# The paths to Freesurfer reconstructions\n",
    "subjects_dir ='../../archive/subjects/'\n",
    "subject = 'fsaverage' # change it to use freesurfer's bem\n",
    "\n",
    "# Compute Source Space (surface)\n",
    "ico = 4 #**************************************************************\n",
    "spacing='ico'+str(ico) \n",
    "src = mne.setup_source_space(subject, spacing=spacing, add_dist='patch',\n",
    "                             subjects_dir=subjects_dir)\n",
    "conductivity = (0.3, 0.0075, 0.3)  #  three layers for EEG (MNE default  (0.3 0.006 0.3) )\n",
    "model = mne.make_bem_model(subject=subject, ico=ico,\n",
    "                           conductivity=conductivity,\n",
    "                           subjects_dir=subjects_dir)\n",
    "# 5 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bem = mne.make_bem_solution(model)\n",
    "\n",
    "trans = './tmsi_trans.fif'\n",
    "# 1m 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view surfaces\n",
    "# plot_bem_kwargs = dict(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     brain_surfaces=\"white\",\n",
    "#     orientation=\"coronal\",\n",
    "#     slices=[50, 100, 150, 200],\n",
    "# )\n",
    "\n",
    "# mne.viz.plot_bem(**plot_bem_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualing the coregistration \n",
    "# info = mne.io.read_info(raw_fname)\n",
    "# # Here we look at the dense head, which isn't used for BEM computations but\n",
    "# # is useful for coregistration.\n",
    "# mne.viz.plot_alignment(\n",
    "#     info,\n",
    "#     trans,\n",
    "#     subject=subject,\n",
    "#     dig=True,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     surfaces=\"pial\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.viz.plot_bem(src=src, **plot_bem_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface = '../../archive/subjects/fsaverage/bem/inner_skull.surf'\n",
    "# vol_src = mne.setup_volume_source_space(\n",
    "#     subject, subjects_dir=subjects_dir, surface=surface, add_interpolator=False\n",
    "# )  # Just for speed!\n",
    "# print(vol_src)\n",
    "\n",
    "# mne.viz.plot_bem(src=vol_src, **plot_bem_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"mri\",\n",
    "#     src=src,\n",
    "# )\n",
    "# mne.viz.set_3d_view(\n",
    "#     fig,\n",
    "#     azimuth=173.78,\n",
    "#     elevation=101.75,\n",
    "#     distance=0.30,\n",
    "#     focalpoint=(-0.03, -0.01, 0.03),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd = mne.make_forward_solution(raw_fname, trans=trans, src=src, bem=bem,\n",
    "                                meg=False, eeg=True, mindist=5.0, n_jobs=2,\n",
    "                                verbose=True)\n",
    "print(fwd)\n",
    "\n",
    "# 10s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lh = fwd[\"src\"][0]  # Visualize the left hemisphere\n",
    "# verts = lh[\"rr\"]  # The vertices of the source space\n",
    "# tris = lh[\"tris\"]  # Groups of three vertices that form triangles\n",
    "# dip_pos = lh[\"rr\"][lh[\"vertno\"]]  # The position of the dipoles\n",
    "# dip_ori = lh[\"nn\"][lh[\"vertno\"]]\n",
    "# dip_len = len(dip_pos)\n",
    "# dip_times = [0]\n",
    "# white = (1.0, 1.0, 1.0)  # RGB values for a white color\n",
    "\n",
    "# actual_amp = np.ones(dip_len)  # misc amp to create Dipole instance\n",
    "# actual_gof = np.ones(dip_len)  # misc GOF to create Dipole instance\n",
    "# dipoles = mne.Dipole(dip_times, dip_pos, actual_amp, dip_ori, actual_gof)\n",
    "# trans = mne.read_trans('tmsi_trans.fif')\n",
    "\n",
    "# fig = mne.viz.create_3d_figure(size=(600, 400), bgcolor=white)\n",
    "# coord_frame = \"mri\"\n",
    "\n",
    "# # Plot the cortex\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=coord_frame,\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# # Mark the position of the dipoles with small red dots\n",
    "# mne.viz.plot_dipole_locations(\n",
    "#     dipoles=dipoles,\n",
    "#     trans=trans,\n",
    "#     mode=\"sphere\",\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     coord_frame=coord_frame,\n",
    "#     scale=7e-4,\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# mne.viz.set_3d_view(figure=fig, azimuth=180, distance=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.create_3d_figure(size=(600, 400))\n",
    "\n",
    "# # Plot the cortex\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"head\",\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# # Show the three dipoles defined at each location in the source space\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     fwd=fwd,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"head\",\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# mne.viz.set_3d_view(figure=fig, azimuth=180, distance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = mne.viz.create_3d_figure(size=(600, 400))\n",
    "\n",
    "# # Plot the cortex\n",
    "# mne.viz.plot_alignment(\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     trans=trans,\n",
    "#     surfaces=\"white\",\n",
    "#     coord_frame=\"head\",\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# # Show the dipoles as arrows pointing along the surface normal\n",
    "# mne.viz.plot_dipole_locations(\n",
    "#     dipoles=dipoles,\n",
    "#     trans=trans,\n",
    "#     mode=\"arrow\",\n",
    "#     subject=subject,\n",
    "#     subjects_dir=subjects_dir,\n",
    "#     coord_frame=\"head\",\n",
    "#     scale=7e-4,\n",
    "#     fig=fig,\n",
    "# )\n",
    "\n",
    "# mne.viz.set_3d_view(figure=fig, azimuth=180, distance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n",
    "                                         use_cps=True)\n",
    "leadfield = fwd_fixed['sol']['data']\n",
    "source_rr=fwd_fixed['source_rr']\n",
    "print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.write_forward_solution('fwd.fif', fwd_fixed, overwrite=True, verbose=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw=mne.io.read_raw_fif(raw_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the entire data as empty room noise\n",
    "noise_cov = mne.compute_raw_covariance(raw)\n",
    "noise_cov_mat=noise_cov['data'] # it only included the good chans\n",
    "# compute the average of the diagonal\n",
    "# construct the scale of the noise cov\n",
    "scale=0.05 # 1% 5% 10% 30% 50% *******************************************************************************\n",
    "scale_ave=np.sqrt(np.mean(noise_cov_mat.diagonal()))*scale\n",
    "sim_cov_mat=np.zeros((np.shape(noise_cov_mat)))\n",
    "for i in range(np.shape(sim_cov_mat)[0]):\n",
    "       sim_cov_mat[i,i]=scale_ave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_cov_mat.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(noise_cov_mat,vmin=-1.5e-10, vmax=1.5e-10, cmap='jet')\n",
    "# plt.colorbar()\n",
    "# np.mean(noise_cov_mat.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cov=noise_cov.copy()\n",
    "sim_cov['data']=sim_cov_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.write_cov('noise_cov.fif', noise_cov, overwrite=True, verbose=None)\n",
    "# mne.write_cov('sim_cov.fif', sim_cov, overwrite=True, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nepochs=int(np.floor(np.shape(preprocessed_eeg)[1]/sampling_freq))\n",
    "# epochs_mat = np.column_stack(\n",
    "#     (\n",
    "#         np.arange(0, np.shape(preprocessed_eeg)[1]-sampling_freq, sampling_freq),\n",
    "#         np.zeros(nepochs, dtype=int),\n",
    "#         np.array([1]*nepochs),\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epoch_dict = dict(resting=1)\n",
    "# epochs = mne.Epochs(raw, epochs_mat, tmin=0, tmax=0.999, event_id=epoch_dict, preload=True, baseline=(None, None))\n",
    "\n",
    "# evoked = epochs[\"resting\"].average()\n",
    "# mne.write_evokeds('resting_ave.fif', evoked, on_mismatch='raise', overwrite=True, verbose=None)\n",
    "# evokeds = mne.read_evokeds('./resting_ave.fif')\n",
    "# resting = evokeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwd = mne.read_forward_solution('fwd.fif')\n",
    "fwd_surf=mne.convert_forward_solution(fwd, surf_ori=True, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the source estimate (Fixed dipole orientations)\n",
    "depth=0.8 # 0.8 1 2 4 ***************************************************************************************\n",
    "# inverse_operator = make_inverse_operator(resting.info, fwd, sim_cov, depth=depth, fixed=True)\n",
    "inverse_operator = make_inverse_operator(raw.info, fwd_surf, sim_cov, depth=depth, fixed=True)\n",
    "# save the inverse operator and the inverse matrix\n",
    "# write_inverse_operator('inv.fif', inverse_operator,overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linearly constrained minimum variance (LCMV) beamformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mne.beamformer import make_lcmv, apply_lcmv, apply_lcmv_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters = make_lcmv(\n",
    "#     raw.info,\n",
    "#     fwd,\n",
    "#     noise_cov,\n",
    "#     reg=0.05,\n",
    "#     noise_cov=noise_cov,\n",
    "#     pick_ori=\"max-power\",\n",
    "#     weight_norm=\"unit-noise-gain\",\n",
    "#     rank=None,\n",
    "# )\n",
    "\n",
    "# # You can save the filter for later use with:\n",
    "# # filters.save('filters-lcmv.h5')\n",
    "\n",
    "# # stc = apply_lcmv(evoked, filters)\n",
    "# stc = apply_lcmv_raw(raw,filters) \n",
    "# # 32s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(stc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters_vec = make_lcmv(\n",
    "#     evoked.info,\n",
    "#     fwd,\n",
    "#     noise_cov,\n",
    "#     reg=0.05,\n",
    "#     noise_cov=sim_cov,\n",
    "#     pick_ori=\"vector\",\n",
    "#     weight_norm=\"unit-noise-gain-invariant\",\n",
    "#     rank=None,\n",
    "# )\n",
    "# # save a bit of memory\n",
    "# # src = fwd_fixed[\"src\"]\n",
    "# # del fwd_fixed\n",
    "# stc_vec = apply_lcmv(evoked, filters_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run extract_invmat.ipynb # run this script to load the functions needed to extract inverse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['MNE','dSPM','sLORETA','eLORETA'] # **********************************************\n",
    "method = methods[0]  # (could also be dSPM or sLORETA)# **********************************************\n",
    "# invmat=_get_matrix_from_inverse_operator(inverse_operator,fwd,method=method,lambda2=1.0/9.0)\n",
    "invmat=_get_matrix_from_inverse_operator(inverse_operator,fwd_fixed,method=method,lambda2=1.0/9.0)\n",
    "np.shape(invmat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not ch_info_bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bad channels from the original eeg\n",
    "if ch_info_bads:\n",
    "    original_eeg=np.delete(preprocessed_eeg,ch_info_bads,0)\n",
    "else:\n",
    "    original_eeg=preprocessed_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct eeg using invmat and leadfield matrix\n",
    "source_data=np.matmul(invmat,original_eeg)\n",
    "EEG_recon=np.matmul(leadfield,source_data)\n",
    "# 11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bad channels from the reconstructed eeg\n",
    "if ch_info_bads:\n",
    "    EEG_recon=np.delete(EEG_recon,ch_info_bads,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0,np.shape(EEG_recon)[1],1),EEG_recon.transpose())\n",
    "# plt.title('reconstructed EEG - all chan')\n",
    "# plt.ylim([-2e-5,2e-5])\n",
    "# # 16 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0,np.shape(EEG_recon)[1],1),EEG_recon[ch_dubious,:].transpose())\n",
    "# plt.title('reconstructed EEG - dubious chan')\n",
    "# plt.ylim([-2e-5,2e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0,np.shape(EEG_recon)[1],1),EEG_recon[ch_bad,:].transpose())\n",
    "# plt.title('reconstructed EEG - bad chan')\n",
    "# plt.ylim([-2e-5,2e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation\n",
    "corr = np.corrcoef(EEG_recon, original_eeg, rowvar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # examine \n",
    "# chan=22 # 12, 30\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(np.arange(np.size(original_eeg,1)),original_eeg[chan,:],'r')\n",
    "# plt.title('original_eeg')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(np.arange(np.size(EEG_recon,1)),EEG_recon[chan,:],'b')\n",
    "# plt.title('reconstructed eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # examine\n",
    "# chan=31 # 12, 30\n",
    "# nsamples=2000\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(np.arange(nsamples),original_eeg[chan,10000:10000+nsamples],'r')\n",
    "# plt.title('original_eeg')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(np.arange(nsamples),EEG_recon[chan,10000:10000+nsamples],'b')\n",
    "# plt.title('reconstructed eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(0,np.shape(EEG_recon)[0],1)+194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr=corr[np.arange(0,np.shape(EEG_recon)[0],1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr=corr[:,np.arange(194,388,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(corr,cmap='jet',vmin=-1,vmax=1)\n",
    "# plt.ylabel('reconstructed EEG (194 good channels)')\n",
    "# plt.xlabel('original EEG (194 good channels)')\n",
    "# plt.title('correlation')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(corr,cmap='jet',vmin=-1,vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.title('corrceof: ico' + str(ico) + ' scale ' +str(scale) +' depth '+ str(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrcoef_diag=np.zeros((np.shape(EEG_recon)[0]))\n",
    "for i in range(np.shape(EEG_recon)[0]):\n",
    "    corrcoef_diag[i]=corr[i,np.shape(EEG_recon)[0]+i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrcoef_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(0, np.shape(EEG_recon)[0],1) ,corrcoef_diag, 'r.')\n",
    "# plt.title('corrceof: ico' + str(ico) + ' scale ' +str(scale) +' depth '+ str(depth))\n",
    "# plt.xlabel('good channels')\n",
    "# plt.ylabel('corrcoef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrcoef_diag # chan 13 (M1) and chan 31(OZ) have lowest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save outputs all in one mat file. \n",
    "# outdict=dict()\n",
    "# outdict['leadfield']=leadfield # leadfield matrix\n",
    "# outdict['invmat']=invmat #  inverse matrix\n",
    "# outdict['source_rr']=source_rr # the source location AND labels (matlab)\n",
    "# outdict['sim_cov_mat']=sim_cov_mat # noise covariance\n",
    "# outdict['scale']=scale # scale\n",
    "# outdict['depth']=depth # depth\n",
    "# outdict['conductivity']=conductivity # 3 layrs conductivity\n",
    "\n",
    "\n",
    "# outdict['ch_bad']=ch_bad #  inverse matrix\n",
    "# outdict['ch_dubious']=ch_dubious # \n",
    "# outdict['ch_names']=ch_names #  \n",
    "# outdict['Coordinates']=Coordinates #  \n",
    "# outdict['corrcoef_diag']=corrcoef_diag #  \n",
    "# outdict['subject_ID']=subject_ID #  \n",
    "\n",
    "# savemat(subject_ID+'_scale_'+str(scale)+'_depth_'+str(depth),outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict=dict()\n",
    "outdict['leadfield']=leadfield # leadfield matrix\n",
    "outdict['invmat']=invmat #  inverse matrix\n",
    "outdict['source_rr']=source_rr # the source location AND labels (matlab)\n",
    "outdict['sim_cov_mat']=sim_cov_mat # noise covariance\n",
    "# stc_data=stc.data\n",
    "# outdict['stc']=stc_data # the source estimate\n",
    "outdict['scale']=scale # scale\n",
    "outdict['depth']=depth # depth\n",
    "outdict['conductivity']=conductivity # 3 layrs conductivity\n",
    "outdict['ch_bad']=ch_bad #  inverse matrix\n",
    "outdict['ch_dubious']=ch_dubious # \n",
    "outdict['ch_names']=ch_names #  \n",
    "outdict['Coordinates']=Coordinates #  \n",
    "outdict['corrcoef_diag']=corrcoef_diag #  \n",
    "outdict['subject_ID']=subject_ID #  \n",
    "savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth),outdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(stc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdict=dict()\n",
    "stc_data=stc.data\n",
    "stc_data1=stc_data[0:1000,:]\n",
    "stc_data2=stc_data[1000:2000,:]\n",
    "stc_data3=stc_data[2000:3000,:]\n",
    "stc_data4=stc_data[3000:4000,:]\n",
    "stc_data5=stc_data[4000::,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stc.save(\"stc.fif\",overwrite=True, ftype='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdict['stc_data']=stc_data # the source estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# scipy.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy==1.11.3\n",
    "# the previous version is 1.9 compatible with sklearn 1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.io.savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data',\n",
    "#                  outdict,oned_as='column',format='5',do_compression=True)\n",
    "# # 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# filename = subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data'\n",
    "# fileObject = open(filename, 'wb')\n",
    "# pkl.dump(stc_data, fileObject)\n",
    "# fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hdf5storage\n",
    "# hdf5storage.__version__\n",
    "# # it was 0.1.18 previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hdf5storage==0.1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data.mat',\n",
    "#         outdict,do_compression=True,format='7.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data1.mat',\n",
    "        {\"stc_data1\": stc_data1},do_compression=True,format='7.3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data2.mat',\n",
    "        {\"stc_data2\": stc_data2},do_compression=True,format='7.3')\n",
    "savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data3.mat',\n",
    "        {\"stc_data3\": stc_data3},do_compression=True,format='7.3')\n",
    "savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data4.mat',\n",
    "        {\"stc_data4\": stc_data4},do_compression=True,format='7.3')\n",
    "savemat(subject_ID +'_method_' + methods[0]+'_ico_'+str(ico)+'_scale_'+str(scale)+'_depth_'+str(depth)+'_st.data5.mat',\n",
    "        {\"stc_data5\": stc_data5},do_compression=True,format='7.3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
