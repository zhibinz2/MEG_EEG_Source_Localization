{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/zhibinz2/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 55 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 61 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 67 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 58 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading forward solution from /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/simple_fsaverage_fixed_fwd.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (81924 sources, 306 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "    366 x 366 full covariance (kind = 1) found.\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n"
     ]
    }
   ],
   "source": [
    "# https://mne.tools/stable/auto_tutorials/inverse/35_dipole_orientations.html\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "\n",
    "data_path = sample.data_path()\n",
    "meg_path = data_path / \"MEG\" / \"sample\"\n",
    "evokeds = mne.read_evokeds(meg_path / \"sample_audvis-ave.fif\")\n",
    "# evokeds = mne.read_evokeds('/home/zhibinz2/Documents/GitHub/CAMCAN_MEG_100/CC120319/rest/rest_raw.fif')\n",
    "left_auditory = evokeds[0].apply_baseline()\n",
    "fwd = mne.read_forward_solution('simple_fsaverage_fixed_fwd.fif')\n",
    "mne.convert_forward_solution(fwd, surf_ori=True, copy=False)\n",
    "noise_cov = mne.read_cov(meg_path / \"sample_audvis-cov.fif\")\n",
    "# noise_cov = mne.read_cov('/home/zhibinz2/Documents/GitHub/CAMCAN_MEG_100/CC120319/rest/rest_raw.fif')\n",
    "subject = \"fsaverage\"\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "# trans_fname = 'sample_fsaverage_manual_trans.fif'\n",
    "trans_fname = '/home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/test_scripts/CAMCAN_fsaverage_trans.fif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse operator with 0 channels.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No channels match the selection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fixed dipole orientations\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Compute the source estimate for the left auditory condition in the sample\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# dataset.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m inv \u001b[39m=\u001b[39m make_inverse_operator(left_auditory\u001b[39m.\u001b[39;49minfo, fwd, noise_cov, fixed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m stc \u001b[39m=\u001b[39m apply_inverse(left_auditory, inv, pick_ori\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m<decorator-gen-492>:12\u001b[0m, in \u001b[0;36mmake_inverse_operator\u001b[0;34m(info, forward, noise_cov, loose, depth, fixed, rank, use_cps, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mne/lib/python3.10/site-packages/mne/minimum_norm/inverse.py:1685\u001b[0m, in \u001b[0;36mmake_inverse_operator\u001b[0;34m(info, forward, noise_cov, loose, depth, fixed, rank, use_cps, verbose)\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[39m# For now we always have pca='white'. It does not seem to affect\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m \u001b[39m# calculations and is also backward-compatible with MNE-C\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m depth \u001b[39m=\u001b[39m _check_depth(depth, \u001b[39m'\u001b[39m\u001b[39mdepth_mne\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1684\u001b[0m forward, gain_info, gain, depth_prior, orient_prior, source_std, \\\n\u001b[0;32m-> 1685\u001b[0m     trace_GRGT, noise_cov, _ \u001b[39m=\u001b[39m _prepare_forward(\n\u001b[1;32m   1686\u001b[0m         forward, info, noise_cov, fixed, loose, rank, pca\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwhite\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m   1687\u001b[0m         use_cps\u001b[39m=\u001b[39;49muse_cps, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdepth)\n\u001b[1;32m   1688\u001b[0m \u001b[39m# no need to copy any attributes of forward here because there is\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[39m# a deepcopy in _prepare_forward\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m inv \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m   1691\u001b[0m     projs\u001b[39m=\u001b[39mdeepcopy(gain_info[\u001b[39m'\u001b[39m\u001b[39mprojs\u001b[39m\u001b[39m'\u001b[39m]), eigen_leads_weighted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1692\u001b[0m     source_ori\u001b[39m=\u001b[39mforward[\u001b[39m'\u001b[39m\u001b[39msource_ori\u001b[39m\u001b[39m'\u001b[39m], mri_head_t\u001b[39m=\u001b[39mforward[\u001b[39m'\u001b[39m\u001b[39mmri_head_t\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m   1693\u001b[0m     nsource\u001b[39m=\u001b[39mforward[\u001b[39m'\u001b[39m\u001b[39mnsource\u001b[39m\u001b[39m'\u001b[39m], units\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAm\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1694\u001b[0m     coord_frame\u001b[39m=\u001b[39mforward[\u001b[39m'\u001b[39m\u001b[39mcoord_frame\u001b[39m\u001b[39m'\u001b[39m], source_nn\u001b[39m=\u001b[39mforward[\u001b[39m'\u001b[39m\u001b[39msource_nn\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     src\u001b[39m=\u001b[39mforward[\u001b[39m'\u001b[39m\u001b[39msrc\u001b[39m\u001b[39m'\u001b[39m], fmri_prior\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, info\u001b[39m=\u001b[39mdeepcopy(forward[\u001b[39m'\u001b[39m\u001b[39minfo\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/mne/lib/python3.10/site-packages/mne/minimum_norm/inverse.py:1549\u001b[0m, in \u001b[0;36m_prepare_forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1545\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mConverting forward solution to surface orientation\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1546\u001b[0m         convert_forward_solution(\n\u001b[1;32m   1547\u001b[0m             forward, surf_ori\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, use_cps\u001b[39m=\u001b[39muse_cps, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1549\u001b[0m forward, info_picked \u001b[39m=\u001b[39m _select_orient_forward(forward, info, noise_cov,\n\u001b[1;32m   1550\u001b[0m                                               copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1551\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mSelected \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m channels\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(info_picked[\u001b[39m'\u001b[39m\u001b[39mch_names\u001b[39m\u001b[39m'\u001b[39m],)))\n\u001b[1;32m   1553\u001b[0m \u001b[39mif\u001b[39;00m exp \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mne/lib/python3.10/site-packages/mne/forward/forward.py:1069\u001b[0m, in \u001b[0;36m_select_orient_forward\u001b[0;34m(forward, info, noise_cov, copy)\u001b[0m\n\u001b[1;32m   1066\u001b[0m forward \u001b[39m=\u001b[39m pick_channels_forward(forward, ch_names, ordered\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1067\u001b[0m                                 copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   1068\u001b[0m info_idx \u001b[39m=\u001b[39m [info[\u001b[39m'\u001b[39m\u001b[39mch_names\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mindex(name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m ch_names]\n\u001b[0;32m-> 1069\u001b[0m info_picked \u001b[39m=\u001b[39m pick_info(info, info_idx)\n\u001b[1;32m   1070\u001b[0m forward[\u001b[39m'\u001b[39m\u001b[39minfo\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39m_check_consistency()\n\u001b[1;32m   1071\u001b[0m info_picked\u001b[39m.\u001b[39m_check_consistency()\n",
      "File \u001b[0;32m<decorator-gen-11>:12\u001b[0m, in \u001b[0;36mpick_info\u001b[0;34m(info, sel, copy, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mne/lib/python3.10/site-packages/mne/io/pick.py:493\u001b[0m, in \u001b[0;36mpick_info\u001b[0;34m(info, sel, copy, verbose)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[39mreturn\u001b[39;00m info\n\u001b[1;32m    492\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(sel) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo channels match the selection.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    494\u001b[0m n_unique \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(info[\u001b[39m'\u001b[39m\u001b[39mch_names\u001b[39m\u001b[39m'\u001b[39m]))[sel]))\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m n_unique \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(sel):\n",
      "\u001b[0;31mValueError\u001b[0m: No channels match the selection."
     ]
    }
   ],
   "source": [
    "# Fixed dipole orientations\n",
    "# Compute the source estimate for the left auditory condition in the sample\n",
    "# dataset.\n",
    "inv = make_inverse_operator(left_auditory.info, fwd, noise_cov, fixed=True)\n",
    "stc = apply_inverse(left_auditory, inv, pick_ori=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mne.tools/stable/auto_tutorials/intro/10_overview.html#sphx-glr-auto-tutorials-intro-10-overview-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 305)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inv['eigen_leads']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: 1 (FIFFV_MNE_MEG)\n",
      "fMRI prior: None\n",
      "Number of sources: 516\n",
      "Number of vertices on the left hemisphere: 163842\n",
      "Number of vertices on the right hemisphere: 163842\n"
     ]
    }
   ],
   "source": [
    "print(\"Method: %s\" % inv[\"methods\"])\n",
    "print(\"fMRI prior: %s\" % inv[\"fmri_prior\"])\n",
    "print(\"Number of sources: %s\" % inv[\"nsource\"])\n",
    "# print(\"Number of channels: %s\" % inv[\"nchan\"])\n",
    "\n",
    "src = inv[\"src\"]  # get the source space\n",
    "\n",
    "# Get access to the triangulation of the cortex\n",
    "print(\"Number of vertices on the left hemisphere: %d\" % len(src[0][\"rr\"]))\n",
    "# print(\"Number of triangles on left hemisphere: %d\" % len(src[0][\"use_tris\"]))\n",
    "print(\"Number of vertices on the right hemisphere: %d\" % len(src[1][\"rr\"]))\n",
    "# print(\"Number of triangles on right hemisphere: %d\" % len(src[1][\"use_tris\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\zhouz\\mne-python\\1.3.1_0\\envs\\mne\\Lib\\site-packages\\mne\\minimum_norm\\resolution_matrix.py\n",
    "# https://github.com/mne-tools/mne-python/blob/main/mne/minimum_norm/resolution_matrix.py\n",
    "\"\"\"Compute resolution matrix for linear estimators.\"\"\"\n",
    "# Authors: olaf.hauk@mrc-cbu.cam.ac.uk\n",
    "#\n",
    "# License: BSD-3-Clause\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mne.minimum_norm.inverse import InverseOperator\n",
    "\n",
    "from mne.forward.forward import convert_forward_solution, Forward\n",
    "\n",
    "from mne import pick_channels_forward, EvokedArray\n",
    "from mne.utils import logger, verbose, _validate_type\n",
    "from mne.forward.forward import convert_forward_solution, Forward\n",
    "from mne.io.constants import FIFF\n",
    "from mne.minimum_norm import apply_inverse\n",
    "from mne.source_estimate import _prepare_label_extraction, _make_stc, _get_src_type\n",
    "from mne.source_space import SourceSpaces, _get_vertno\n",
    "from mne.label import Label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@verbose\n",
    "def make_inverse_resolution_matrix(\n",
    "    forward, inverse_operator, method=\"dSPM\", lambda2=1.0 / 9.0, verbose=None\n",
    "):\n",
    "    \"\"\"Compute resolution matrix for linear inverse operator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    forward : instance of Forward\n",
    "        Forward Operator.\n",
    "    inverse_operator : instance of InverseOperator\n",
    "        Inverse operator.\n",
    "    method : 'MNE' | 'dSPM' | 'sLORETA'\n",
    "        Inverse method to use (MNE, dSPM, sLORETA).\n",
    "    lambda2 : float\n",
    "        The regularisation parameter.\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resmat: array, shape (n_orient_inv * n_dipoles, n_orient_fwd * n_dipoles)\n",
    "        Resolution matrix (inverse operator times forward operator).\n",
    "        The result of applying the inverse operator to the forward operator.\n",
    "        If source orientations are not fixed, all source components will be\n",
    "        computed (i.e. for n_orient_inv > 1 or n_orient_fwd > 1).\n",
    "        The columns of the resolution matrix are the point-spread functions\n",
    "        (PSFs) and the rows are the cross-talk functions (CTFs).\n",
    "    \"\"\"\n",
    "    # make sure forward and inverse operator match\n",
    "    inv = inverse_operator\n",
    "    fwd = _convert_forward_match_inv(forward, inv)\n",
    "\n",
    "    # don't include bad channels\n",
    "    # only use good channels from inverse operator\n",
    "    bads_inv = inv[\"info\"][\"bads\"]\n",
    "    # good channels\n",
    "    ch_names = [c for c in inv[\"info\"][\"ch_names\"] if (c not in bads_inv)]\n",
    "    fwd = pick_channels_forward(fwd, ch_names, ordered=True)\n",
    "\n",
    "    # get leadfield matrix from forward solution\n",
    "    leadfield = fwd[\"sol\"][\"data\"]\n",
    "    invmat = _get_matrix_from_inverse_operator(inv, fwd, method=method, lambda2=lambda2)\n",
    "    resmat = invmat.dot(leadfield)\n",
    "    logger.info(\"Dimensions of resolution matrix: %d by %d.\" % resmat.shape)\n",
    "    return resmat\n",
    "\n",
    "\n",
    "@verbose\n",
    "def _get_psf_ctf(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    *,\n",
    "    func,\n",
    "    mode,\n",
    "    n_comp,\n",
    "    norm,\n",
    "    return_pca_vars,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get point-spread (PSFs) or cross-talk (CTFs) functions.\"\"\"\n",
    "    # check for consistencies in input parameters\n",
    "    _check_get_psf_ctf_params(mode, n_comp, return_pca_vars)\n",
    "\n",
    "    # backward compatibility\n",
    "    if norm is True:\n",
    "        norm = \"max\"\n",
    "\n",
    "    # get relevant vertices in source space\n",
    "    src_orig = src\n",
    "    _validate_type(src_orig, (InverseOperator, Forward, SourceSpaces), \"src\")\n",
    "    if not isinstance(src, SourceSpaces):\n",
    "        src = src[\"src\"]\n",
    "    verts_all = _vertices_for_get_psf_ctf(idx, src)\n",
    "    vertno = _get_vertno(src)\n",
    "    n_verts = sum(len(v) for v in vertno)\n",
    "    src_type = _get_src_type(src, vertno)\n",
    "    subject = src._subject\n",
    "    if vector and src_type == \"surface\":\n",
    "        _validate_type(\n",
    "            src_orig,\n",
    "            (Forward, InverseOperator),\n",
    "            \"src\",\n",
    "            extra=\"when creating a vector surface source estimate\",\n",
    "        )\n",
    "        nn = src_orig[\"source_nn\"]\n",
    "    else:\n",
    "        nn = np.repeat(np.eye(3, 3)[np.newaxis], n_verts, 0)\n",
    "\n",
    "    n_r, n_c = resmat.shape\n",
    "    if ((n_verts != n_r) and (n_r / 3 != n_verts)) or (\n",
    "        (n_verts != n_c) and (n_c / 3 != n_verts)\n",
    "    ):\n",
    "        msg = (\n",
    "            \"Number of vertices (%d) and corresponding dimension of\"\n",
    "            \"resolution matrix (%d, %d) do not match\" % (n_verts, n_r, n_c)\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # the following will operate on columns of funcs\n",
    "    if func == \"ctf\":\n",
    "        resmat = resmat.T\n",
    "        n_r, n_c = n_c, n_r\n",
    "\n",
    "    # Functions and variances per label\n",
    "    stcs = []\n",
    "    pca_vars = []\n",
    "\n",
    "    # if 3 orientations per vertex, redefine indices to columns of resolution\n",
    "    # matrix\n",
    "    if n_verts != n_c:\n",
    "        # change indices to three indices per vertex\n",
    "        for [i, verts] in enumerate(verts_all):\n",
    "            verts_vec = np.empty(3 * len(verts), dtype=int)\n",
    "            for [j, v] in enumerate(verts):\n",
    "                verts_vec[3 * j : 3 * j + 3] = 3 * verts[j] + np.array([0, 1, 2])\n",
    "            verts_all[i] = verts_vec  # use these as indices\n",
    "\n",
    "    for verts in verts_all:\n",
    "        # get relevant PSFs or CTFs for specified vertices\n",
    "        if type(verts) is int:\n",
    "            verts = [verts]  # to keep array dimensions\n",
    "        funcs = resmat[:, verts]\n",
    "\n",
    "        # normalise PSFs/CTFs if requested\n",
    "        if norm is not None:\n",
    "            funcs = _normalise_psf_ctf(funcs, norm)\n",
    "\n",
    "        # summarise PSFs/CTFs across vertices if requested\n",
    "        pca_var = None  # variances computed only if return_pca_vars=True\n",
    "        if mode is not None:\n",
    "            funcs, pca_var = _summarise_psf_ctf(\n",
    "                funcs, mode, n_comp, return_pca_vars, nn\n",
    "            )\n",
    "\n",
    "        if not vector:  # if one value per vertex requested\n",
    "            if n_verts != n_r:  # if 3 orientations per vertex, combine\n",
    "                funcs_int = np.empty([int(n_r / 3), funcs.shape[1]])\n",
    "                for i in np.arange(0, n_verts):\n",
    "                    funcs_vert = funcs[3 * i : 3 * i + 3, :]\n",
    "                    funcs_int[i, :] = np.sqrt((funcs_vert**2).sum(axis=0))\n",
    "                funcs = funcs_int\n",
    "\n",
    "        stc = _make_stc(\n",
    "            funcs,\n",
    "            vertno,\n",
    "            src_type,\n",
    "            tmin=0.0,\n",
    "            tstep=1.0,\n",
    "            subject=subject,\n",
    "            vector=vector,\n",
    "            source_nn=nn,\n",
    "        )\n",
    "        stcs.append(stc)\n",
    "        pca_vars.append(pca_var)\n",
    "\n",
    "    # if just one list or label specified, simplify output\n",
    "    if len(stcs) == 1:\n",
    "        stcs = stc\n",
    "    if len(pca_vars) == 1:\n",
    "        pca_vars = pca_var\n",
    "    if pca_var is not None:\n",
    "        return stcs, pca_vars\n",
    "    else:\n",
    "        return stcs\n",
    "\n",
    "\n",
    "def _check_get_psf_ctf_params(mode, n_comp, return_pca_vars):\n",
    "    \"\"\"Check input parameters of _get_psf_ctf() for consistency.\"\"\"\n",
    "    if mode in [None, \"sum\", \"mean\"] and n_comp > 1:\n",
    "        msg = \"n_comp must be 1 for mode=%s.\" % mode\n",
    "        raise ValueError(msg)\n",
    "    if mode != \"pca\" and return_pca_vars:\n",
    "        msg = \"SVD variances can only be returned if mode=\" \"pca\" \".\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "\n",
    "def _vertices_for_get_psf_ctf(idx, src):\n",
    "    \"\"\"Get vertices in source space for PSFs/CTFs in _get_psf_ctf().\"\"\"\n",
    "    # idx must be list\n",
    "    # if label(s) specified get the indices, otherwise just carry on\n",
    "    if type(idx[0]) is Label:\n",
    "        # specify without source time courses, gets indices per label\n",
    "        verts_labs, _ = _prepare_label_extraction(\n",
    "            stc=None,\n",
    "            labels=idx,\n",
    "            src=src,\n",
    "            mode=\"mean\",\n",
    "            allow_empty=False,\n",
    "            use_sparse=False,\n",
    "        )\n",
    "        # verts_labs can be list of lists\n",
    "        # concatenate indices per label across hemispheres\n",
    "        # one list item per label\n",
    "        verts = []\n",
    "\n",
    "        for v in verts_labs:\n",
    "            # if two hemispheres present\n",
    "            if type(v) is list:\n",
    "                # indices for both hemispheres in one list\n",
    "                this_verts = np.concatenate((v[0], v[1]))\n",
    "            else:\n",
    "                this_verts = np.array(v)\n",
    "            verts.append(this_verts)\n",
    "    # check if list of list or just list\n",
    "    else:\n",
    "        if isinstance(idx[0], list):  # if list of list of integers\n",
    "            verts = idx\n",
    "        else:  # if list of integers\n",
    "            verts = [idx]\n",
    "\n",
    "    return verts\n",
    "\n",
    "\n",
    "def _normalise_psf_ctf(funcs, norm):\n",
    "    \"\"\"Normalise PSFs/CTFs in _get_psf_ctf().\"\"\"\n",
    "    # normalise PSFs/CTFs if specified\n",
    "    if norm == \"max\":\n",
    "        maxval = max(-funcs.min(), funcs.max())\n",
    "        funcs = funcs / maxval\n",
    "    elif norm == \"norm\":  # normalise to maximum norm across columns\n",
    "        norms = np.linalg.norm(funcs, axis=0)\n",
    "        funcs = funcs / norms.max()\n",
    "\n",
    "    return funcs\n",
    "\n",
    "\n",
    "def _summarise_psf_ctf(funcs, mode, n_comp, return_pca_vars, nn):\n",
    "    \"\"\"Summarise PSFs/CTFs across vertices.\"\"\"\n",
    "    s_var = None  # only computed for return_pca_vars=True\n",
    "\n",
    "    if mode == \"maxval\":  # pick PSF/CTF with maximum absolute value\n",
    "        absvals = np.maximum(-np.min(funcs, axis=0), np.max(funcs, axis=0))\n",
    "        if n_comp > 1:  # only keep requested number of sorted PSFs/CTFs\n",
    "            sortidx = np.argsort(absvals)\n",
    "            maxidx = sortidx[-n_comp:]\n",
    "        else:  # faster if only one required\n",
    "            maxidx = [absvals.argmax()]\n",
    "        funcs = funcs[:, maxidx]\n",
    "\n",
    "    elif mode == \"maxnorm\":  # pick PSF/CTF with maximum norm\n",
    "        norms = np.linalg.norm(funcs, axis=0)\n",
    "        if n_comp > 1:  # only keep requested number of sorted PSFs/CTFs\n",
    "            sortidx = np.argsort(norms)\n",
    "            maxidx = sortidx[-n_comp:]\n",
    "        else:  # faster if only one required\n",
    "            maxidx = [norms.argmax()]\n",
    "        funcs = funcs[:, maxidx]\n",
    "\n",
    "    elif mode == \"sum\":  # sum across PSFs/CTFs\n",
    "        funcs = np.sum(funcs, axis=1, keepdims=True)\n",
    "\n",
    "    elif mode == \"mean\":  # mean of PSFs/CTFs\n",
    "        funcs = np.mean(funcs, axis=1, keepdims=True)\n",
    "\n",
    "    elif mode == \"pca\":  # SVD across PSFs/CTFs\n",
    "        # compute SVD of PSFs/CTFs across vertices\n",
    "        u, s, _ = np.linalg.svd(funcs, full_matrices=False, compute_uv=True)\n",
    "        if n_comp > 1:\n",
    "            funcs = u[:, :n_comp]\n",
    "        else:\n",
    "            funcs = u[:, 0, np.newaxis]\n",
    "        # if explained variances for SVD components requested\n",
    "        if return_pca_vars:\n",
    "            # explained variance of individual SVD components\n",
    "            s2 = s * s\n",
    "            s_var = 100 * s2[:n_comp] / s2.sum()\n",
    "\n",
    "    return funcs, s_var\n",
    "\n",
    "\n",
    "@verbose\n",
    "def get_point_spread(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    mode=None,\n",
    "    *,\n",
    "    n_comp=1,\n",
    "    norm=False,\n",
    "    return_pca_vars=False,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get point-spread (PSFs) functions for vertices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resmat : array, shape (n_dipoles, n_dipoles)\n",
    "        Forward Operator.\n",
    "    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n",
    "        Source space used to compute resolution matrix.\n",
    "        Must be an InverseOperator if ``vector=True`` and a surface\n",
    "        source space is used.\n",
    "    %(idx_pctf)s\n",
    "    %(mode_pctf)s\n",
    "    %(n_comp_pctf_n)s\n",
    "    %(norm_pctf)s\n",
    "    %(return_pca_vars_pctf)s\n",
    "    %(vector_pctf)s\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    %(stcs_pctf)s\n",
    "    %(pca_vars_pctf)s\n",
    "    \"\"\"  # noqa: E501\n",
    "    return _get_psf_ctf(\n",
    "        resmat,\n",
    "        src,\n",
    "        idx,\n",
    "        func=\"psf\",\n",
    "        mode=mode,\n",
    "        n_comp=n_comp,\n",
    "        norm=norm,\n",
    "        return_pca_vars=return_pca_vars,\n",
    "        vector=vector,\n",
    "    )\n",
    "\n",
    "\n",
    "@verbose\n",
    "def get_cross_talk(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    mode=None,\n",
    "    *,\n",
    "    n_comp=1,\n",
    "    norm=False,\n",
    "    return_pca_vars=False,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get cross-talk (CTFs) function for vertices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resmat : array, shape (n_dipoles, n_dipoles)\n",
    "        Forward Operator.\n",
    "    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n",
    "        Source space used to compute resolution matrix.\n",
    "        Must be an InverseOperator if ``vector=True`` and a surface\n",
    "        source space is used.\n",
    "    %(idx_pctf)s\n",
    "    %(mode_pctf)s\n",
    "    %(n_comp_pctf_n)s\n",
    "    %(norm_pctf)s\n",
    "    %(return_pca_vars_pctf)s\n",
    "    %(vector_pctf)s\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    %(stcs_pctf)s\n",
    "    %(pca_vars_pctf)s\n",
    "    \"\"\"  # noqa: E501\n",
    "    return _get_psf_ctf(\n",
    "        resmat,\n",
    "        src,\n",
    "        idx,\n",
    "        func=\"ctf\",\n",
    "        mode=mode,\n",
    "        n_comp=n_comp,\n",
    "        norm=norm,\n",
    "        return_pca_vars=return_pca_vars,\n",
    "        vector=vector,\n",
    "    )\n",
    "\n",
    "\n",
    "def _convert_forward_match_inv(fwd, inv):\n",
    "    \"\"\"Ensure forward and inverse operators match.\n",
    "\n",
    "    Inverse operator and forward operator must have same surface orientations,\n",
    "    but can have different source orientation constraints.\n",
    "    \"\"\"\n",
    "    _validate_type(fwd, Forward, \"fwd\")\n",
    "    _validate_type(inv, InverseOperator, \"inverse_operator\")\n",
    "    # did inverse operator use fixed orientation?\n",
    "    is_fixed_inv = _check_fixed_ori(inv)\n",
    "    # did forward operator use fixed orientation?\n",
    "    is_fixed_fwd = _check_fixed_ori(fwd)\n",
    "\n",
    "    # if inv or fwd fixed: do nothing\n",
    "    # if inv loose: surf_ori must be True\n",
    "    # if inv free: surf_ori must be False\n",
    "    if not is_fixed_inv and not is_fixed_fwd:\n",
    "        inv_surf_ori = inv._is_surf_ori\n",
    "        if inv_surf_ori != fwd[\"surf_ori\"]:\n",
    "            fwd = convert_forward_solution(\n",
    "                fwd, surf_ori=inv_surf_ori, force_fixed=False\n",
    "            )\n",
    "\n",
    "    return fwd\n",
    "\n",
    "\n",
    "def _prepare_info(inverse_operator):\n",
    "    \"\"\"Get a usable dict.\"\"\"\n",
    "    # in order to convert sub-leadfield matrix to evoked data type (pretending\n",
    "    # it's an epoch, see in loop below), uses 'info' from inverse solution\n",
    "    # because this has all the correct projector information\n",
    "    info = deepcopy(inverse_operator[\"info\"])\n",
    "    with info._unlock():\n",
    "        info[\"sfreq\"] = 1000.0  # necessary\n",
    "        info[\"projs\"] = inverse_operator[\"projs\"]\n",
    "        info[\"custom_ref_applied\"] = False\n",
    "    return info\n",
    "\n",
    "\n",
    "def _get_matrix_from_inverse_operator(\n",
    "    inverse_operator, forward, method=\"dSPM\", lambda2=1.0 / 9.0\n",
    "):\n",
    "    \"\"\"Get inverse matrix from an inverse operator.\n",
    "\n",
    "    Currently works only for fixed/loose orientation constraints\n",
    "    For loose orientation constraint, the CTFs are computed for the normal\n",
    "    component (pick_ori='normal').\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inverse_operator : instance of InverseOperator\n",
    "        The inverse operator.\n",
    "    forward : instance of Forward\n",
    "        The forward operator.\n",
    "    method : 'MNE' | 'dSPM' | 'sLORETA'\n",
    "        Inverse methods (for apply_inverse).\n",
    "    lambda2 : float\n",
    "        The regularization parameter (for apply_inverse).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    invmat : array, shape (n_dipoles, n_channels)\n",
    "        Inverse matrix associated with inverse operator and specified\n",
    "        parameters.\n",
    "    \"\"\"\n",
    "    # make sure forward and inverse operators match with respect to\n",
    "    # surface orientation\n",
    "    _convert_forward_match_inv(forward, inverse_operator)\n",
    "\n",
    "    info_inv = _prepare_info(inverse_operator)\n",
    "\n",
    "    # only use channels that are good for inverse operator and forward sol\n",
    "    ch_names_inv = info_inv[\"ch_names\"]\n",
    "    n_chs_inv = len(ch_names_inv)\n",
    "    bads_inv = inverse_operator[\"info\"][\"bads\"]\n",
    "\n",
    "    # indices of bad channels\n",
    "    ch_idx_bads = [ch_names_inv.index(ch) for ch in bads_inv]\n",
    "\n",
    "    # create identity matrix as input for inverse operator\n",
    "    # set elements to zero for non-selected channels\n",
    "    id_mat = np.eye(n_chs_inv)\n",
    "\n",
    "    # convert identity matrix to evoked data type (pretending it's an epoch)\n",
    "    ev_id = EvokedArray(id_mat, info=info_inv, tmin=0.0)\n",
    "\n",
    "    # apply inverse operator to identity matrix in order to get inverse matrix\n",
    "    # free orientation constraint not possible because apply_inverse would\n",
    "    # combine components\n",
    "\n",
    "    # check if inverse operator uses fixed source orientations\n",
    "    is_fixed_inv = _check_fixed_ori(inverse_operator)\n",
    "\n",
    "    # choose pick_ori according to inverse operator\n",
    "    if is_fixed_inv:\n",
    "        pick_ori = None\n",
    "    else:\n",
    "        pick_ori = \"vector\"\n",
    "\n",
    "    # columns for bad channels will be zero\n",
    "    invmat_op = apply_inverse(\n",
    "        ev_id, inverse_operator, lambda2=lambda2, method=method, pick_ori=pick_ori\n",
    "    )\n",
    "\n",
    "    # turn source estimate into numpy array\n",
    "    invmat = invmat_op.data\n",
    "\n",
    "    # remove columns for bad channels\n",
    "    # take into account it may be 3D array\n",
    "    invmat = np.delete(invmat, ch_idx_bads, axis=invmat.ndim - 1)\n",
    "\n",
    "    # if 3D array, i.e. multiple values per location (fixed and loose),\n",
    "    # reshape into 2D array\n",
    "    if invmat.ndim == 3:\n",
    "        v0o1 = invmat[0, 1].copy()\n",
    "        v3o2 = invmat[3, 2].copy()\n",
    "        shape = invmat.shape\n",
    "        invmat = invmat.reshape(shape[0] * shape[1], shape[2])\n",
    "        # make sure that reshaping worked\n",
    "        assert np.array_equal(v0o1, invmat[1])\n",
    "        assert np.array_equal(v3o2, invmat[11])\n",
    "\n",
    "    logger.info(\"Dimension of Inverse Matrix: %s\" % str(invmat.shape))\n",
    "\n",
    "    return invmat\n",
    "\n",
    "\n",
    "def _check_fixed_ori(inst):\n",
    "    \"\"\"Check if inverse or forward was computed for fixed orientations.\"\"\"\n",
    "    is_fixed = inst[\"source_ori\"] != FIFF.FIFFV_MNE_FREE_ORI\n",
    "    return is_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Created the whitener using a noise covariance matrix with rank 302 (3 small eigenvalues omitted)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying inverse operator to \"\"...\n",
      "    Picked 305 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  36.6% variance\n",
      "[done]\n",
      "Dimension of Inverse Matrix: (516, 305)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(516, 305)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invmat=_get_matrix_from_inverse_operator(inv,fwd,method='MNE',lambda2=1.0/9.0)\n",
    "np.shape(invmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.85717925e+01, -1.00134862e+02, -7.88067242e+03, ...,\n",
       "        -2.33709624e+01,  6.40099017e+00, -7.90479678e+02],\n",
       "       [ 1.18211694e+02, -3.39999508e+02,  3.78470015e+03, ...,\n",
       "        -5.14322801e+01, -1.32193969e+00, -2.54505325e+03],\n",
       "       [-5.41852673e+01,  1.61213497e+02,  4.62975037e+04, ...,\n",
       "        -1.03714272e+02,  2.07629844e+02, -3.34030613e+03],\n",
       "       ...,\n",
       "       [-1.14399842e+02,  1.79495827e+01,  9.26187376e+02, ...,\n",
       "        -5.53187364e+02, -6.99500305e+01, -9.40582357e+03],\n",
       "       [-1.03640156e+02,  6.60830664e+01, -1.38198165e+03, ...,\n",
       "         3.37254073e+01, -5.42632091e+01, -6.28843889e+02],\n",
       "       [-1.31064101e+02,  8.08653965e+01,  1.43244730e+03, ...,\n",
       "         1.87633513e+02,  8.95785283e+01, -1.56040084e+04]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdf5storage import loadmat, savemat \n",
    "outdict=dict()\n",
    "outdict['invmat']=invmat\n",
    "savemat('invmat',outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.70414206e-03,  9.01998980e-03, -4.88370534e-05, ...,\n",
       "        -1.16493218e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-2.24937839e-02,  8.04135275e-02, -1.70128731e-02, ...,\n",
       "        -1.28684682e-02, -2.92337917e-01,  5.31978372e-01],\n",
       "       [-1.27147202e-03,  2.83104573e-03,  4.67616436e-03, ...,\n",
       "        -2.13050669e-02,  2.71901985e-02,  1.37320972e-02],\n",
       "       ...,\n",
       "       [ 2.06551194e-02, -4.20096612e-02, -2.37951968e-02, ...,\n",
       "         1.53227250e-05, -7.09451534e-03, -3.20832935e-02],\n",
       "       [ 1.37148723e-02, -1.89503104e-02, -6.86345693e-03, ...,\n",
       "        -6.56069957e-03,  2.54723438e-02,  1.44327039e-02],\n",
       "       [ 1.64094089e-02, -3.04125005e-02, -1.93479185e-02, ...,\n",
       "         3.24758819e-02, -3.91917304e-02, -5.05716630e-02]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv['eigen_leads']['data']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
