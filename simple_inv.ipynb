{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/zhibinz2/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 55 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 61 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 67 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 58 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading forward solution from /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/simple_fsaverage_fwd.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (516 sources, 306 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "    366 x 366 full covariance (kind = 1) found.\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n"
     ]
    }
   ],
   "source": [
    "# https://mne.tools/stable/auto_tutorials/inverse/35_dipole_orientations.html\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "\n",
    "data_path = sample.data_path()\n",
    "meg_path = data_path / \"MEG\" / \"sample\"\n",
    "evokeds = mne.read_evokeds(meg_path / \"sample_audvis-ave.fif\")\n",
    "left_auditory = evokeds[0].apply_baseline()\n",
    "fwd = mne.read_forward_solution('simple_fsaverage_fwd.fif')\n",
    "mne.convert_forward_solution(fwd, surf_ori=True, copy=False)\n",
    "noise_cov = mne.read_cov(meg_path / \"sample_audvis-cov.fif\")\n",
    "# subject = 'sample'\n",
    "subject = \"fsaverage\"\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "trans_fname = 'sample_fsaverage_manual_trans.fif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse operator with 305 channels.\n",
      "    305 out of 306 channels remain after picking\n",
      "Selected 305 channels\n",
      "Creating the depth weighting matrix...\n",
      "    203 planar channels\n",
      "    limit = 486/516 = 10.012531\n",
      "    scale = 4.50069e-08 exp = 0.8\n",
      "    Picked elements from a free-orientation depth-weighting prior into the fixed-orientation one\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 3.3e-13 (2.2e-16 eps * 305 dim * 4.8  max singular value)\n",
      "    Estimated rank (mag + grad): 302\n",
      "    MEG: rank 302 computed from 305 data channels with 3 projectors\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 6.71359\n",
      "    scaling factor to adjust the trace = 8.33631e+17 (nchan = 305 nzero = 3)\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 55\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Created the whitener using a noise covariance matrix with rank 302 (3 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Applying inverse operator to \"Left Auditory\"...\n",
      "    Picked 305 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  54.7% variance\n",
      "    dSPM...\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# Fixed dipole orientations\n",
    "# Compute the source estimate for the left auditory condition in the sample\n",
    "# dataset.\n",
    "inv = make_inverse_operator(left_auditory.info, fwd, noise_cov, fixed=True)\n",
    "stc = apply_inverse(left_auditory, inv, pick_ori=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 305)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inv['eigen_leads']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: 1 (FIFFV_MNE_MEG)\n",
      "fMRI prior: None\n",
      "Number of sources: 516\n",
      "Number of vertices on the left hemisphere: 163842\n",
      "Number of vertices on the right hemisphere: 163842\n"
     ]
    }
   ],
   "source": [
    "print(\"Method: %s\" % inv[\"methods\"])\n",
    "print(\"fMRI prior: %s\" % inv[\"fmri_prior\"])\n",
    "print(\"Number of sources: %s\" % inv[\"nsource\"])\n",
    "# print(\"Number of channels: %s\" % inv[\"nchan\"])\n",
    "\n",
    "src = inv[\"src\"]  # get the source space\n",
    "\n",
    "# Get access to the triangulation of the cortex\n",
    "print(\"Number of vertices on the left hemisphere: %d\" % len(src[0][\"rr\"]))\n",
    "# print(\"Number of triangles on left hemisphere: %d\" % len(src[0][\"use_tris\"]))\n",
    "print(\"Number of vertices on the right hemisphere: %d\" % len(src[1][\"rr\"]))\n",
    "# print(\"Number of triangles on right hemisphere: %d\" % len(src[1][\"use_tris\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\zhouz\\mne-python\\1.3.1_0\\envs\\mne\\Lib\\site-packages\\mne\\minimum_norm\\resolution_matrix.py\n",
    "# https://github.com/mne-tools/mne-python/blob/main/mne/minimum_norm/resolution_matrix.py\n",
    "\"\"\"Compute resolution matrix for linear estimators.\"\"\"\n",
    "# Authors: olaf.hauk@mrc-cbu.cam.ac.uk\n",
    "#\n",
    "# License: BSD-3-Clause\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mne.minimum_norm.inverse import InverseOperator\n",
    "\n",
    "from mne.forward.forward import convert_forward_solution, Forward\n",
    "\n",
    "from mne import pick_channels_forward, EvokedArray\n",
    "from mne.utils import logger, verbose, _validate_type\n",
    "from mne.forward.forward import convert_forward_solution, Forward\n",
    "from mne.io.constants import FIFF\n",
    "from mne.minimum_norm import apply_inverse\n",
    "from mne.source_estimate import _prepare_label_extraction, _make_stc, _get_src_type\n",
    "from mne.source_space import SourceSpaces, _get_vertno\n",
    "from mne.label import Label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@verbose\n",
    "def make_inverse_resolution_matrix(\n",
    "    forward, inverse_operator, method=\"dSPM\", lambda2=1.0 / 9.0, verbose=None\n",
    "):\n",
    "    \"\"\"Compute resolution matrix for linear inverse operator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    forward : instance of Forward\n",
    "        Forward Operator.\n",
    "    inverse_operator : instance of InverseOperator\n",
    "        Inverse operator.\n",
    "    method : 'MNE' | 'dSPM' | 'sLORETA'\n",
    "        Inverse method to use (MNE, dSPM, sLORETA).\n",
    "    lambda2 : float\n",
    "        The regularisation parameter.\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resmat: array, shape (n_orient_inv * n_dipoles, n_orient_fwd * n_dipoles)\n",
    "        Resolution matrix (inverse operator times forward operator).\n",
    "        The result of applying the inverse operator to the forward operator.\n",
    "        If source orientations are not fixed, all source components will be\n",
    "        computed (i.e. for n_orient_inv > 1 or n_orient_fwd > 1).\n",
    "        The columns of the resolution matrix are the point-spread functions\n",
    "        (PSFs) and the rows are the cross-talk functions (CTFs).\n",
    "    \"\"\"\n",
    "    # make sure forward and inverse operator match\n",
    "    inv = inverse_operator\n",
    "    fwd = _convert_forward_match_inv(forward, inv)\n",
    "\n",
    "    # don't include bad channels\n",
    "    # only use good channels from inverse operator\n",
    "    bads_inv = inv[\"info\"][\"bads\"]\n",
    "    # good channels\n",
    "    ch_names = [c for c in inv[\"info\"][\"ch_names\"] if (c not in bads_inv)]\n",
    "    fwd = pick_channels_forward(fwd, ch_names, ordered=True)\n",
    "\n",
    "    # get leadfield matrix from forward solution\n",
    "    leadfield = fwd[\"sol\"][\"data\"]\n",
    "    invmat = _get_matrix_from_inverse_operator(inv, fwd, method=method, lambda2=lambda2)\n",
    "    resmat = invmat.dot(leadfield)\n",
    "    logger.info(\"Dimensions of resolution matrix: %d by %d.\" % resmat.shape)\n",
    "    return resmat\n",
    "\n",
    "\n",
    "@verbose\n",
    "def _get_psf_ctf(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    *,\n",
    "    func,\n",
    "    mode,\n",
    "    n_comp,\n",
    "    norm,\n",
    "    return_pca_vars,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get point-spread (PSFs) or cross-talk (CTFs) functions.\"\"\"\n",
    "    # check for consistencies in input parameters\n",
    "    _check_get_psf_ctf_params(mode, n_comp, return_pca_vars)\n",
    "\n",
    "    # backward compatibility\n",
    "    if norm is True:\n",
    "        norm = \"max\"\n",
    "\n",
    "    # get relevant vertices in source space\n",
    "    src_orig = src\n",
    "    _validate_type(src_orig, (InverseOperator, Forward, SourceSpaces), \"src\")\n",
    "    if not isinstance(src, SourceSpaces):\n",
    "        src = src[\"src\"]\n",
    "    verts_all = _vertices_for_get_psf_ctf(idx, src)\n",
    "    vertno = _get_vertno(src)\n",
    "    n_verts = sum(len(v) for v in vertno)\n",
    "    src_type = _get_src_type(src, vertno)\n",
    "    subject = src._subject\n",
    "    if vector and src_type == \"surface\":\n",
    "        _validate_type(\n",
    "            src_orig,\n",
    "            (Forward, InverseOperator),\n",
    "            \"src\",\n",
    "            extra=\"when creating a vector surface source estimate\",\n",
    "        )\n",
    "        nn = src_orig[\"source_nn\"]\n",
    "    else:\n",
    "        nn = np.repeat(np.eye(3, 3)[np.newaxis], n_verts, 0)\n",
    "\n",
    "    n_r, n_c = resmat.shape\n",
    "    if ((n_verts != n_r) and (n_r / 3 != n_verts)) or (\n",
    "        (n_verts != n_c) and (n_c / 3 != n_verts)\n",
    "    ):\n",
    "        msg = (\n",
    "            \"Number of vertices (%d) and corresponding dimension of\"\n",
    "            \"resolution matrix (%d, %d) do not match\" % (n_verts, n_r, n_c)\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # the following will operate on columns of funcs\n",
    "    if func == \"ctf\":\n",
    "        resmat = resmat.T\n",
    "        n_r, n_c = n_c, n_r\n",
    "\n",
    "    # Functions and variances per label\n",
    "    stcs = []\n",
    "    pca_vars = []\n",
    "\n",
    "    # if 3 orientations per vertex, redefine indices to columns of resolution\n",
    "    # matrix\n",
    "    if n_verts != n_c:\n",
    "        # change indices to three indices per vertex\n",
    "        for [i, verts] in enumerate(verts_all):\n",
    "            verts_vec = np.empty(3 * len(verts), dtype=int)\n",
    "            for [j, v] in enumerate(verts):\n",
    "                verts_vec[3 * j : 3 * j + 3] = 3 * verts[j] + np.array([0, 1, 2])\n",
    "            verts_all[i] = verts_vec  # use these as indices\n",
    "\n",
    "    for verts in verts_all:\n",
    "        # get relevant PSFs or CTFs for specified vertices\n",
    "        if type(verts) is int:\n",
    "            verts = [verts]  # to keep array dimensions\n",
    "        funcs = resmat[:, verts]\n",
    "\n",
    "        # normalise PSFs/CTFs if requested\n",
    "        if norm is not None:\n",
    "            funcs = _normalise_psf_ctf(funcs, norm)\n",
    "\n",
    "        # summarise PSFs/CTFs across vertices if requested\n",
    "        pca_var = None  # variances computed only if return_pca_vars=True\n",
    "        if mode is not None:\n",
    "            funcs, pca_var = _summarise_psf_ctf(\n",
    "                funcs, mode, n_comp, return_pca_vars, nn\n",
    "            )\n",
    "\n",
    "        if not vector:  # if one value per vertex requested\n",
    "            if n_verts != n_r:  # if 3 orientations per vertex, combine\n",
    "                funcs_int = np.empty([int(n_r / 3), funcs.shape[1]])\n",
    "                for i in np.arange(0, n_verts):\n",
    "                    funcs_vert = funcs[3 * i : 3 * i + 3, :]\n",
    "                    funcs_int[i, :] = np.sqrt((funcs_vert**2).sum(axis=0))\n",
    "                funcs = funcs_int\n",
    "\n",
    "        stc = _make_stc(\n",
    "            funcs,\n",
    "            vertno,\n",
    "            src_type,\n",
    "            tmin=0.0,\n",
    "            tstep=1.0,\n",
    "            subject=subject,\n",
    "            vector=vector,\n",
    "            source_nn=nn,\n",
    "        )\n",
    "        stcs.append(stc)\n",
    "        pca_vars.append(pca_var)\n",
    "\n",
    "    # if just one list or label specified, simplify output\n",
    "    if len(stcs) == 1:\n",
    "        stcs = stc\n",
    "    if len(pca_vars) == 1:\n",
    "        pca_vars = pca_var\n",
    "    if pca_var is not None:\n",
    "        return stcs, pca_vars\n",
    "    else:\n",
    "        return stcs\n",
    "\n",
    "\n",
    "def _check_get_psf_ctf_params(mode, n_comp, return_pca_vars):\n",
    "    \"\"\"Check input parameters of _get_psf_ctf() for consistency.\"\"\"\n",
    "    if mode in [None, \"sum\", \"mean\"] and n_comp > 1:\n",
    "        msg = \"n_comp must be 1 for mode=%s.\" % mode\n",
    "        raise ValueError(msg)\n",
    "    if mode != \"pca\" and return_pca_vars:\n",
    "        msg = \"SVD variances can only be returned if mode=\" \"pca\" \".\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "\n",
    "def _vertices_for_get_psf_ctf(idx, src):\n",
    "    \"\"\"Get vertices in source space for PSFs/CTFs in _get_psf_ctf().\"\"\"\n",
    "    # idx must be list\n",
    "    # if label(s) specified get the indices, otherwise just carry on\n",
    "    if type(idx[0]) is Label:\n",
    "        # specify without source time courses, gets indices per label\n",
    "        verts_labs, _ = _prepare_label_extraction(\n",
    "            stc=None,\n",
    "            labels=idx,\n",
    "            src=src,\n",
    "            mode=\"mean\",\n",
    "            allow_empty=False,\n",
    "            use_sparse=False,\n",
    "        )\n",
    "        # verts_labs can be list of lists\n",
    "        # concatenate indices per label across hemispheres\n",
    "        # one list item per label\n",
    "        verts = []\n",
    "\n",
    "        for v in verts_labs:\n",
    "            # if two hemispheres present\n",
    "            if type(v) is list:\n",
    "                # indices for both hemispheres in one list\n",
    "                this_verts = np.concatenate((v[0], v[1]))\n",
    "            else:\n",
    "                this_verts = np.array(v)\n",
    "            verts.append(this_verts)\n",
    "    # check if list of list or just list\n",
    "    else:\n",
    "        if isinstance(idx[0], list):  # if list of list of integers\n",
    "            verts = idx\n",
    "        else:  # if list of integers\n",
    "            verts = [idx]\n",
    "\n",
    "    return verts\n",
    "\n",
    "\n",
    "def _normalise_psf_ctf(funcs, norm):\n",
    "    \"\"\"Normalise PSFs/CTFs in _get_psf_ctf().\"\"\"\n",
    "    # normalise PSFs/CTFs if specified\n",
    "    if norm == \"max\":\n",
    "        maxval = max(-funcs.min(), funcs.max())\n",
    "        funcs = funcs / maxval\n",
    "    elif norm == \"norm\":  # normalise to maximum norm across columns\n",
    "        norms = np.linalg.norm(funcs, axis=0)\n",
    "        funcs = funcs / norms.max()\n",
    "\n",
    "    return funcs\n",
    "\n",
    "\n",
    "def _summarise_psf_ctf(funcs, mode, n_comp, return_pca_vars, nn):\n",
    "    \"\"\"Summarise PSFs/CTFs across vertices.\"\"\"\n",
    "    s_var = None  # only computed for return_pca_vars=True\n",
    "\n",
    "    if mode == \"maxval\":  # pick PSF/CTF with maximum absolute value\n",
    "        absvals = np.maximum(-np.min(funcs, axis=0), np.max(funcs, axis=0))\n",
    "        if n_comp > 1:  # only keep requested number of sorted PSFs/CTFs\n",
    "            sortidx = np.argsort(absvals)\n",
    "            maxidx = sortidx[-n_comp:]\n",
    "        else:  # faster if only one required\n",
    "            maxidx = [absvals.argmax()]\n",
    "        funcs = funcs[:, maxidx]\n",
    "\n",
    "    elif mode == \"maxnorm\":  # pick PSF/CTF with maximum norm\n",
    "        norms = np.linalg.norm(funcs, axis=0)\n",
    "        if n_comp > 1:  # only keep requested number of sorted PSFs/CTFs\n",
    "            sortidx = np.argsort(norms)\n",
    "            maxidx = sortidx[-n_comp:]\n",
    "        else:  # faster if only one required\n",
    "            maxidx = [norms.argmax()]\n",
    "        funcs = funcs[:, maxidx]\n",
    "\n",
    "    elif mode == \"sum\":  # sum across PSFs/CTFs\n",
    "        funcs = np.sum(funcs, axis=1, keepdims=True)\n",
    "\n",
    "    elif mode == \"mean\":  # mean of PSFs/CTFs\n",
    "        funcs = np.mean(funcs, axis=1, keepdims=True)\n",
    "\n",
    "    elif mode == \"pca\":  # SVD across PSFs/CTFs\n",
    "        # compute SVD of PSFs/CTFs across vertices\n",
    "        u, s, _ = np.linalg.svd(funcs, full_matrices=False, compute_uv=True)\n",
    "        if n_comp > 1:\n",
    "            funcs = u[:, :n_comp]\n",
    "        else:\n",
    "            funcs = u[:, 0, np.newaxis]\n",
    "        # if explained variances for SVD components requested\n",
    "        if return_pca_vars:\n",
    "            # explained variance of individual SVD components\n",
    "            s2 = s * s\n",
    "            s_var = 100 * s2[:n_comp] / s2.sum()\n",
    "\n",
    "    return funcs, s_var\n",
    "\n",
    "\n",
    "@verbose\n",
    "def get_point_spread(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    mode=None,\n",
    "    *,\n",
    "    n_comp=1,\n",
    "    norm=False,\n",
    "    return_pca_vars=False,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get point-spread (PSFs) functions for vertices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resmat : array, shape (n_dipoles, n_dipoles)\n",
    "        Forward Operator.\n",
    "    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n",
    "        Source space used to compute resolution matrix.\n",
    "        Must be an InverseOperator if ``vector=True`` and a surface\n",
    "        source space is used.\n",
    "    %(idx_pctf)s\n",
    "    %(mode_pctf)s\n",
    "    %(n_comp_pctf_n)s\n",
    "    %(norm_pctf)s\n",
    "    %(return_pca_vars_pctf)s\n",
    "    %(vector_pctf)s\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    %(stcs_pctf)s\n",
    "    %(pca_vars_pctf)s\n",
    "    \"\"\"  # noqa: E501\n",
    "    return _get_psf_ctf(\n",
    "        resmat,\n",
    "        src,\n",
    "        idx,\n",
    "        func=\"psf\",\n",
    "        mode=mode,\n",
    "        n_comp=n_comp,\n",
    "        norm=norm,\n",
    "        return_pca_vars=return_pca_vars,\n",
    "        vector=vector,\n",
    "    )\n",
    "\n",
    "\n",
    "@verbose\n",
    "def get_cross_talk(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    mode=None,\n",
    "    *,\n",
    "    n_comp=1,\n",
    "    norm=False,\n",
    "    return_pca_vars=False,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get cross-talk (CTFs) function for vertices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resmat : array, shape (n_dipoles, n_dipoles)\n",
    "        Forward Operator.\n",
    "    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n",
    "        Source space used to compute resolution matrix.\n",
    "        Must be an InverseOperator if ``vector=True`` and a surface\n",
    "        source space is used.\n",
    "    %(idx_pctf)s\n",
    "    %(mode_pctf)s\n",
    "    %(n_comp_pctf_n)s\n",
    "    %(norm_pctf)s\n",
    "    %(return_pca_vars_pctf)s\n",
    "    %(vector_pctf)s\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    %(stcs_pctf)s\n",
    "    %(pca_vars_pctf)s\n",
    "    \"\"\"  # noqa: E501\n",
    "    return _get_psf_ctf(\n",
    "        resmat,\n",
    "        src,\n",
    "        idx,\n",
    "        func=\"ctf\",\n",
    "        mode=mode,\n",
    "        n_comp=n_comp,\n",
    "        norm=norm,\n",
    "        return_pca_vars=return_pca_vars,\n",
    "        vector=vector,\n",
    "    )\n",
    "\n",
    "\n",
    "def _convert_forward_match_inv(fwd, inv):\n",
    "    \"\"\"Ensure forward and inverse operators match.\n",
    "\n",
    "    Inverse operator and forward operator must have same surface orientations,\n",
    "    but can have different source orientation constraints.\n",
    "    \"\"\"\n",
    "    _validate_type(fwd, Forward, \"fwd\")\n",
    "    _validate_type(inv, InverseOperator, \"inverse_operator\")\n",
    "    # did inverse operator use fixed orientation?\n",
    "    is_fixed_inv = _check_fixed_ori(inv)\n",
    "    # did forward operator use fixed orientation?\n",
    "    is_fixed_fwd = _check_fixed_ori(fwd)\n",
    "\n",
    "    # if inv or fwd fixed: do nothing\n",
    "    # if inv loose: surf_ori must be True\n",
    "    # if inv free: surf_ori must be False\n",
    "    if not is_fixed_inv and not is_fixed_fwd:\n",
    "        inv_surf_ori = inv._is_surf_ori\n",
    "        if inv_surf_ori != fwd[\"surf_ori\"]:\n",
    "            fwd = convert_forward_solution(\n",
    "                fwd, surf_ori=inv_surf_ori, force_fixed=False\n",
    "            )\n",
    "\n",
    "    return fwd\n",
    "\n",
    "\n",
    "def _prepare_info(inverse_operator):\n",
    "    \"\"\"Get a usable dict.\"\"\"\n",
    "    # in order to convert sub-leadfield matrix to evoked data type (pretending\n",
    "    # it's an epoch, see in loop below), uses 'info' from inverse solution\n",
    "    # because this has all the correct projector information\n",
    "    info = deepcopy(inverse_operator[\"info\"])\n",
    "    with info._unlock():\n",
    "        info[\"sfreq\"] = 1000.0  # necessary\n",
    "        info[\"projs\"] = inverse_operator[\"projs\"]\n",
    "        info[\"custom_ref_applied\"] = False\n",
    "    return info\n",
    "\n",
    "\n",
    "def _get_matrix_from_inverse_operator(\n",
    "    inverse_operator, forward, method=\"dSPM\", lambda2=1.0 / 9.0\n",
    "):\n",
    "    \"\"\"Get inverse matrix from an inverse operator.\n",
    "\n",
    "    Currently works only for fixed/loose orientation constraints\n",
    "    For loose orientation constraint, the CTFs are computed for the normal\n",
    "    component (pick_ori='normal').\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inverse_operator : instance of InverseOperator\n",
    "        The inverse operator.\n",
    "    forward : instance of Forward\n",
    "        The forward operator.\n",
    "    method : 'MNE' | 'dSPM' | 'sLORETA'\n",
    "        Inverse methods (for apply_inverse).\n",
    "    lambda2 : float\n",
    "        The regularization parameter (for apply_inverse).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    invmat : array, shape (n_dipoles, n_channels)\n",
    "        Inverse matrix associated with inverse operator and specified\n",
    "        parameters.\n",
    "    \"\"\"\n",
    "    # make sure forward and inverse operators match with respect to\n",
    "    # surface orientation\n",
    "    _convert_forward_match_inv(forward, inverse_operator)\n",
    "\n",
    "    info_inv = _prepare_info(inverse_operator)\n",
    "\n",
    "    # only use channels that are good for inverse operator and forward sol\n",
    "    ch_names_inv = info_inv[\"ch_names\"]\n",
    "    n_chs_inv = len(ch_names_inv)\n",
    "    bads_inv = inverse_operator[\"info\"][\"bads\"]\n",
    "\n",
    "    # indices of bad channels\n",
    "    ch_idx_bads = [ch_names_inv.index(ch) for ch in bads_inv]\n",
    "\n",
    "    # create identity matrix as input for inverse operator\n",
    "    # set elements to zero for non-selected channels\n",
    "    id_mat = np.eye(n_chs_inv)\n",
    "\n",
    "    # convert identity matrix to evoked data type (pretending it's an epoch)\n",
    "    ev_id = EvokedArray(id_mat, info=info_inv, tmin=0.0)\n",
    "\n",
    "    # apply inverse operator to identity matrix in order to get inverse matrix\n",
    "    # free orientation constraint not possible because apply_inverse would\n",
    "    # combine components\n",
    "\n",
    "    # check if inverse operator uses fixed source orientations\n",
    "    is_fixed_inv = _check_fixed_ori(inverse_operator)\n",
    "\n",
    "    # choose pick_ori according to inverse operator\n",
    "    if is_fixed_inv:\n",
    "        pick_ori = None\n",
    "    else:\n",
    "        pick_ori = \"vector\"\n",
    "\n",
    "    # columns for bad channels will be zero\n",
    "    invmat_op = apply_inverse(\n",
    "        ev_id, inverse_operator, lambda2=lambda2, method=method, pick_ori=pick_ori\n",
    "    )\n",
    "\n",
    "    # turn source estimate into numpy array\n",
    "    invmat = invmat_op.data\n",
    "\n",
    "    # remove columns for bad channels\n",
    "    # take into account it may be 3D array\n",
    "    invmat = np.delete(invmat, ch_idx_bads, axis=invmat.ndim - 1)\n",
    "\n",
    "    # if 3D array, i.e. multiple values per location (fixed and loose),\n",
    "    # reshape into 2D array\n",
    "    if invmat.ndim == 3:\n",
    "        v0o1 = invmat[0, 1].copy()\n",
    "        v3o2 = invmat[3, 2].copy()\n",
    "        shape = invmat.shape\n",
    "        invmat = invmat.reshape(shape[0] * shape[1], shape[2])\n",
    "        # make sure that reshaping worked\n",
    "        assert np.array_equal(v0o1, invmat[1])\n",
    "        assert np.array_equal(v3o2, invmat[11])\n",
    "\n",
    "    logger.info(\"Dimension of Inverse Matrix: %s\" % str(invmat.shape))\n",
    "\n",
    "    return invmat\n",
    "\n",
    "\n",
    "def _check_fixed_ori(inst):\n",
    "    \"\"\"Check if inverse or forward was computed for fixed orientations.\"\"\"\n",
    "    is_fixed = inst[\"source_ori\"] != FIFF.FIFFV_MNE_FREE_ORI\n",
    "    return is_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Created the whitener using a noise covariance matrix with rank 302 (3 small eigenvalues omitted)\n",
      "Applying inverse operator to \"\"...\n",
      "    Picked 305 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  36.6% variance\n",
      "[done]\n",
      "Dimension of Inverse Matrix: (516, 305)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(516, 305)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invmat=_get_matrix_from_inverse_operator(inv,fwd,method='MNE',lambda2=1.0/9.0)\n",
    "np.shape(invmat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
