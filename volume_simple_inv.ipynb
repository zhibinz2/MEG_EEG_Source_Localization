{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/test_scripts/evoked-ave.fif ...\n",
      "    Read a total of 8 projection items:\n",
      "        mag_ssp_upright.fif : PCA-mags-v1 (1 x 306) active\n",
      "        mag_ssp_upright.fif : PCA-mags-v2 (1 x 306) active\n",
      "        mag_ssp_upright.fif : PCA-mags-v3 (1 x 306) active\n",
      "        mag_ssp_upright.fif : PCA-mags-v4 (1 x 306) active\n",
      "        mag_ssp_upright.fif : PCA-mags-v5 (1 x 306) active\n",
      "        grad_ssp_upright.fif : PCA-grad-v1 (1 x 306) active\n",
      "        grad_ssp_upright.fif : PCA-grad-v2 (1 x 306) active\n",
      "        grad_ssp_upright.fif : PCA-grad-v3 (1 x 306) active\n",
      "    Found the data of interest:\n",
      "        t =    -300.00 ...     700.00 ms (auditory/left)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 7 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.3, 0] sec)\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading forward solution from /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/volume_fwd.fif...\n",
      "    Reading a source space...\n",
      "    [done]\n",
      "    1 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (14629 sources, 306 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "    306 x 306 full covariance (kind = 1) found.\n",
      "    Read a total of 8 projection items:\n",
      "        mag_ssp_upright.fif : PCA-mags-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-mags-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-mags-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-mags-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-mags-v5 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-grad-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-grad-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-grad-v3 (1 x 306)  idle\n"
     ]
    }
   ],
   "source": [
    "# https://mne.tools/stable/auto_tutorials/inverse/35_dipole_orientations.html\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "\n",
    "data_path = sample.data_path()\n",
    "meg_path = data_path / \"MEG\" / \"sample\"\n",
    "# evokeds = mne.read_evokeds(meg_path / \"sample_audvis-ave.fif\")\n",
    "# evokeds = mne.read_evokeds('/home/zhibinz2/Documents/GitHub/CAMCAN_MEG_100/CC120319/rest/rest_raw.fif')\n",
    "evokeds = mne.read_evokeds('./test_scripts/evoked-ave.fif')\n",
    "left_auditory = evokeds[0].apply_baseline()\n",
    "# fwd = mne.read_forward_solution('simple_fsaverage_fixed_fwd.fif')\n",
    "fwd = mne.read_forward_solution('volume_fwd.fif')\n",
    "# mne.convert_forward_solution(fwd, surf_ori=True, copy=False)\n",
    "# noise_cov = mne.read_cov(meg_path / \"sample_audvis-cov.fif\")\n",
    "noise_cov = mne.read_cov('./test_scripts/CAMCAN-cov.fif')\n",
    "# noise_cov = mne.read_cov('/home/zhibinz2/Documents/GitHub/CAMCAN_MEG_100/CC120319/rest/rest_raw.fif')\n",
    "subject = \"fsaverage\"\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "# trans_fname = 'sample_fsaverage_manual_trans.fif'\n",
    "trans_fname = '/home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/test_scripts/CAMCAN_fsaverage_trans.fif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>July 03, 2012  10:32:32 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>MEG</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>66 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.03 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>330.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Projections</th>\n",
       "        <td>mag_ssp_upright.fif : PCA-mags-v1 : on<br/>mag_ssp_upright.fif : PCA-mags-v2 : on<br/>mag_ssp_upright.fif : PCA-mags-v3 : on<br/>mag_ssp_upright.fif : PCA-mags-v4 : on<br/>mag_ssp_upright.fif : PCA-mags-v5 : on<br/>grad_ssp_upright.fif : PCA-grad-v1 : on<br/>grad_ssp_upright.fif : PCA-grad-v2 : on<br/>grad_ssp_upright.fif : PCA-grad-v3 : on</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 24 non-empty values\n",
       " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
       " bads: []\n",
       " ch_names: MEG0113, MEG0112, MEG0111, MEG0122, MEG0123, MEG0121, MEG0132, ...\n",
       " chs: 204 Gradiometers, 102 Magnetometers\n",
       " custom_ref_applied: False\n",
       " description: (meg) Vectorview system at Cambridge\n",
       " dev_head_t: MEG device -> head transform\n",
       " dig: 66 items (3 Cardinal, 5 HPI, 58 Extra)\n",
       " events: 1 item (list)\n",
       " experimenter: MEG\n",
       " file_id: 4 items (dict)\n",
       " highpass: 0.0 Hz\n",
       " hpi_meas: 1 item (list)\n",
       " hpi_results: 1 item (list)\n",
       " hpi_subsystem: 3 items (dict)\n",
       " line_freq: 50.0\n",
       " lowpass: 330.0 Hz\n",
       " maxshield: False\n",
       " meas_date: 2012-07-03 10:32:32 UTC\n",
       " meas_id: 4 items (dict)\n",
       " nchan: 306\n",
       " proj_id: 1 item (ndarray)\n",
       " proj_name: camcan\n",
       " projs: mag_ssp_upright.fif : PCA-mags-v1: on, mag_ssp_upright.fif : ...\n",
       " sfreq: 1000.0 Hz\n",
       " subject_info: 6 items (dict)\n",
       ">"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_auditory.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing inverse operator with 306 channels.\n",
      "    306 out of 306 channels remain after picking\n",
      "Selected 306 channels\n",
      "Creating the depth weighting matrix...\n",
      "    204 planar channels\n",
      "    limit = 13417/14629 = 10.000902\n",
      "    scale = 6.17261e-08 exp = 0.8\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 8)\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 1.5e-08 (2.2e-16 eps * 306 dim * 2.1e+05  max singular value)\n",
      "    Estimated rank (mag + grad): 298\n",
      "    MEG: rank 298 computed from 306 data channels with 8 projectors\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 5.35993\n",
      "    scaling factor to adjust the trace = 3.27377e+19 (nchan = 306 nzero = 8)\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 7\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 8)\n",
      "    Created the whitener using a noise covariance matrix with rank 298 (8 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Applying inverse operator to \"auditory/left\"...\n",
      "    Picked 306 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  41.0% variance\n",
      "    Combining the current components...\n",
      "    dSPM...\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# Fixed dipole orientations\n",
    "# Compute the source estimate for the left auditory condition in the sample\n",
    "# dataset.\n",
    "# inv = make_inverse_operator(left_auditory.info, fwd, noise_cov, fixed=True)\n",
    "inv = make_inverse_operator(left_auditory.info, fwd, noise_cov, fixed=False)\n",
    "stc = apply_inverse(left_auditory, inv, pick_ori=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Write inverse operator decomposition in /home/zhibinz2/Documents/GitHub/MEG_EEG_Source_Localization/CAMCAN_inv.fif...\n",
      "    Write a source space...\n",
      "    [done]\n",
      "    1 source spaces written\n",
      "    Writing inverse operator info...\n",
      "    Writing noise covariance matrix.\n",
      "    Writing source covariance matrix.\n",
      "    Writing orientation priors.\n",
      "    [done]\n"
     ]
    }
   ],
   "source": [
    "# https://mne.tools/stable/auto_tutorials/inverse/30_mne_dspm_loreta.html#compute-inverse-solution\n",
    "from mne.minimum_norm import write_inverse_operator\n",
    "write_inverse_operator('CAMCAN_inv.fif', inv, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mne.tools/stable/auto_tutorials/intro/10_overview.html#sphx-glr-auto-tutorials-intro-10-overview-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43887, 306)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inv['eigen_leads']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: 1 (FIFFV_MNE_MEG)\n",
      "fMRI prior: None\n",
      "Number of sources: 5124\n",
      "Number of vertices on the left hemisphere: 163842\n",
      "Number of vertices on the right hemisphere: 163842\n"
     ]
    }
   ],
   "source": [
    "print(\"Method: %s\" % inv[\"methods\"])\n",
    "print(\"fMRI prior: %s\" % inv[\"fmri_prior\"])\n",
    "print(\"Number of sources: %s\" % inv[\"nsource\"])\n",
    "# print(\"Number of channels: %s\" % inv[\"nchan\"])\n",
    "\n",
    "src = inv[\"src\"]  # get the source space\n",
    "\n",
    "# Get access to the triangulation of the cortex\n",
    "print(\"Number of vertices on the left hemisphere: %d\" % len(src[0][\"rr\"]))\n",
    "# print(\"Number of triangles on left hemisphere: %d\" % len(src[0][\"use_tris\"]))\n",
    "print(\"Number of vertices on the right hemisphere: %d\" % len(src[1][\"rr\"]))\n",
    "# print(\"Number of triangles on right hemisphere: %d\" % len(src[1][\"use_tris\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\zhouz\\mne-python\\1.3.1_0\\envs\\mne\\Lib\\site-packages\\mne\\minimum_norm\\resolution_matrix.py\n",
    "# https://github.com/mne-tools/mne-python/blob/main/mne/minimum_norm/resolution_matrix.py\n",
    "\"\"\"Compute resolution matrix for linear estimators.\"\"\"\n",
    "# Authors: olaf.hauk@mrc-cbu.cam.ac.uk\n",
    "#\n",
    "# License: BSD-3-Clause\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mne.minimum_norm.inverse import InverseOperator\n",
    "\n",
    "from mne.forward.forward import convert_forward_solution, Forward\n",
    "\n",
    "from mne import pick_channels_forward, EvokedArray\n",
    "from mne.utils import logger, verbose, _validate_type\n",
    "from mne.forward.forward import convert_forward_solution, Forward\n",
    "from mne.io.constants import FIFF\n",
    "from mne.minimum_norm import apply_inverse\n",
    "from mne.source_estimate import _prepare_label_extraction, _make_stc, _get_src_type\n",
    "from mne.source_space import SourceSpaces, _get_vertno\n",
    "from mne.label import Label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@verbose\n",
    "def make_inverse_resolution_matrix(\n",
    "    forward, inverse_operator, method=\"dSPM\", lambda2=1.0 / 9.0, verbose=None\n",
    "):\n",
    "    \"\"\"Compute resolution matrix for linear inverse operator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    forward : instance of Forward\n",
    "        Forward Operator.\n",
    "    inverse_operator : instance of InverseOperator\n",
    "        Inverse operator.\n",
    "    method : 'MNE' | 'dSPM' | 'sLORETA'\n",
    "        Inverse method to use (MNE, dSPM, sLORETA).\n",
    "    lambda2 : float\n",
    "        The regularisation parameter.\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resmat: array, shape (n_orient_inv * n_dipoles, n_orient_fwd * n_dipoles)\n",
    "        Resolution matrix (inverse operator times forward operator).\n",
    "        The result of applying the inverse operator to the forward operator.\n",
    "        If source orientations are not fixed, all source components will be\n",
    "        computed (i.e. for n_orient_inv > 1 or n_orient_fwd > 1).\n",
    "        The columns of the resolution matrix are the point-spread functions\n",
    "        (PSFs) and the rows are the cross-talk functions (CTFs).\n",
    "    \"\"\"\n",
    "    # make sure forward and inverse operator match\n",
    "    inv = inverse_operator\n",
    "    fwd = _convert_forward_match_inv(forward, inv)\n",
    "\n",
    "    # don't include bad channels\n",
    "    # only use good channels from inverse operator\n",
    "    bads_inv = inv[\"info\"][\"bads\"]\n",
    "    # good channels\n",
    "    ch_names = [c for c in inv[\"info\"][\"ch_names\"] if (c not in bads_inv)]\n",
    "    fwd = pick_channels_forward(fwd, ch_names, ordered=True)\n",
    "\n",
    "    # get leadfield matrix from forward solution\n",
    "    leadfield = fwd[\"sol\"][\"data\"]\n",
    "    invmat = _get_matrix_from_inverse_operator(inv, fwd, method=method, lambda2=lambda2)\n",
    "    resmat = invmat.dot(leadfield)\n",
    "    logger.info(\"Dimensions of resolution matrix: %d by %d.\" % resmat.shape)\n",
    "    return resmat\n",
    "\n",
    "\n",
    "@verbose\n",
    "def _get_psf_ctf(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    *,\n",
    "    func,\n",
    "    mode,\n",
    "    n_comp,\n",
    "    norm,\n",
    "    return_pca_vars,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get point-spread (PSFs) or cross-talk (CTFs) functions.\"\"\"\n",
    "    # check for consistencies in input parameters\n",
    "    _check_get_psf_ctf_params(mode, n_comp, return_pca_vars)\n",
    "\n",
    "    # backward compatibility\n",
    "    if norm is True:\n",
    "        norm = \"max\"\n",
    "\n",
    "    # get relevant vertices in source space\n",
    "    src_orig = src\n",
    "    _validate_type(src_orig, (InverseOperator, Forward, SourceSpaces), \"src\")\n",
    "    if not isinstance(src, SourceSpaces):\n",
    "        src = src[\"src\"]\n",
    "    verts_all = _vertices_for_get_psf_ctf(idx, src)\n",
    "    vertno = _get_vertno(src)\n",
    "    n_verts = sum(len(v) for v in vertno)\n",
    "    src_type = _get_src_type(src, vertno)\n",
    "    subject = src._subject\n",
    "    if vector and src_type == \"surface\":\n",
    "        _validate_type(\n",
    "            src_orig,\n",
    "            (Forward, InverseOperator),\n",
    "            \"src\",\n",
    "            extra=\"when creating a vector surface source estimate\",\n",
    "        )\n",
    "        nn = src_orig[\"source_nn\"]\n",
    "    else:\n",
    "        nn = np.repeat(np.eye(3, 3)[np.newaxis], n_verts, 0)\n",
    "\n",
    "    n_r, n_c = resmat.shape\n",
    "    if ((n_verts != n_r) and (n_r / 3 != n_verts)) or (\n",
    "        (n_verts != n_c) and (n_c / 3 != n_verts)\n",
    "    ):\n",
    "        msg = (\n",
    "            \"Number of vertices (%d) and corresponding dimension of\"\n",
    "            \"resolution matrix (%d, %d) do not match\" % (n_verts, n_r, n_c)\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # the following will operate on columns of funcs\n",
    "    if func == \"ctf\":\n",
    "        resmat = resmat.T\n",
    "        n_r, n_c = n_c, n_r\n",
    "\n",
    "    # Functions and variances per label\n",
    "    stcs = []\n",
    "    pca_vars = []\n",
    "\n",
    "    # if 3 orientations per vertex, redefine indices to columns of resolution\n",
    "    # matrix\n",
    "    if n_verts != n_c:\n",
    "        # change indices to three indices per vertex\n",
    "        for [i, verts] in enumerate(verts_all):\n",
    "            verts_vec = np.empty(3 * len(verts), dtype=int)\n",
    "            for [j, v] in enumerate(verts):\n",
    "                verts_vec[3 * j : 3 * j + 3] = 3 * verts[j] + np.array([0, 1, 2])\n",
    "            verts_all[i] = verts_vec  # use these as indices\n",
    "\n",
    "    for verts in verts_all:\n",
    "        # get relevant PSFs or CTFs for specified vertices\n",
    "        if type(verts) is int:\n",
    "            verts = [verts]  # to keep array dimensions\n",
    "        funcs = resmat[:, verts]\n",
    "\n",
    "        # normalise PSFs/CTFs if requested\n",
    "        if norm is not None:\n",
    "            funcs = _normalise_psf_ctf(funcs, norm)\n",
    "\n",
    "        # summarise PSFs/CTFs across vertices if requested\n",
    "        pca_var = None  # variances computed only if return_pca_vars=True\n",
    "        if mode is not None:\n",
    "            funcs, pca_var = _summarise_psf_ctf(\n",
    "                funcs, mode, n_comp, return_pca_vars, nn\n",
    "            )\n",
    "\n",
    "        if not vector:  # if one value per vertex requested\n",
    "            if n_verts != n_r:  # if 3 orientations per vertex, combine\n",
    "                funcs_int = np.empty([int(n_r / 3), funcs.shape[1]])\n",
    "                for i in np.arange(0, n_verts):\n",
    "                    funcs_vert = funcs[3 * i : 3 * i + 3, :]\n",
    "                    funcs_int[i, :] = np.sqrt((funcs_vert**2).sum(axis=0))\n",
    "                funcs = funcs_int\n",
    "\n",
    "        stc = _make_stc(\n",
    "            funcs,\n",
    "            vertno,\n",
    "            src_type,\n",
    "            tmin=0.0,\n",
    "            tstep=1.0,\n",
    "            subject=subject,\n",
    "            vector=vector,\n",
    "            source_nn=nn,\n",
    "        )\n",
    "        stcs.append(stc)\n",
    "        pca_vars.append(pca_var)\n",
    "\n",
    "    # if just one list or label specified, simplify output\n",
    "    if len(stcs) == 1:\n",
    "        stcs = stc\n",
    "    if len(pca_vars) == 1:\n",
    "        pca_vars = pca_var\n",
    "    if pca_var is not None:\n",
    "        return stcs, pca_vars\n",
    "    else:\n",
    "        return stcs\n",
    "\n",
    "\n",
    "def _check_get_psf_ctf_params(mode, n_comp, return_pca_vars):\n",
    "    \"\"\"Check input parameters of _get_psf_ctf() for consistency.\"\"\"\n",
    "    if mode in [None, \"sum\", \"mean\"] and n_comp > 1:\n",
    "        msg = \"n_comp must be 1 for mode=%s.\" % mode\n",
    "        raise ValueError(msg)\n",
    "    if mode != \"pca\" and return_pca_vars:\n",
    "        msg = \"SVD variances can only be returned if mode=\" \"pca\" \".\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "\n",
    "def _vertices_for_get_psf_ctf(idx, src):\n",
    "    \"\"\"Get vertices in source space for PSFs/CTFs in _get_psf_ctf().\"\"\"\n",
    "    # idx must be list\n",
    "    # if label(s) specified get the indices, otherwise just carry on\n",
    "    if type(idx[0]) is Label:\n",
    "        # specify without source time courses, gets indices per label\n",
    "        verts_labs, _ = _prepare_label_extraction(\n",
    "            stc=None,\n",
    "            labels=idx,\n",
    "            src=src,\n",
    "            mode=\"mean\",\n",
    "            allow_empty=False,\n",
    "            use_sparse=False,\n",
    "        )\n",
    "        # verts_labs can be list of lists\n",
    "        # concatenate indices per label across hemispheres\n",
    "        # one list item per label\n",
    "        verts = []\n",
    "\n",
    "        for v in verts_labs:\n",
    "            # if two hemispheres present\n",
    "            if type(v) is list:\n",
    "                # indices for both hemispheres in one list\n",
    "                this_verts = np.concatenate((v[0], v[1]))\n",
    "            else:\n",
    "                this_verts = np.array(v)\n",
    "            verts.append(this_verts)\n",
    "    # check if list of list or just list\n",
    "    else:\n",
    "        if isinstance(idx[0], list):  # if list of list of integers\n",
    "            verts = idx\n",
    "        else:  # if list of integers\n",
    "            verts = [idx]\n",
    "\n",
    "    return verts\n",
    "\n",
    "\n",
    "def _normalise_psf_ctf(funcs, norm):\n",
    "    \"\"\"Normalise PSFs/CTFs in _get_psf_ctf().\"\"\"\n",
    "    # normalise PSFs/CTFs if specified\n",
    "    if norm == \"max\":\n",
    "        maxval = max(-funcs.min(), funcs.max())\n",
    "        funcs = funcs / maxval\n",
    "    elif norm == \"norm\":  # normalise to maximum norm across columns\n",
    "        norms = np.linalg.norm(funcs, axis=0)\n",
    "        funcs = funcs / norms.max()\n",
    "\n",
    "    return funcs\n",
    "\n",
    "\n",
    "def _summarise_psf_ctf(funcs, mode, n_comp, return_pca_vars, nn):\n",
    "    \"\"\"Summarise PSFs/CTFs across vertices.\"\"\"\n",
    "    s_var = None  # only computed for return_pca_vars=True\n",
    "\n",
    "    if mode == \"maxval\":  # pick PSF/CTF with maximum absolute value\n",
    "        absvals = np.maximum(-np.min(funcs, axis=0), np.max(funcs, axis=0))\n",
    "        if n_comp > 1:  # only keep requested number of sorted PSFs/CTFs\n",
    "            sortidx = np.argsort(absvals)\n",
    "            maxidx = sortidx[-n_comp:]\n",
    "        else:  # faster if only one required\n",
    "            maxidx = [absvals.argmax()]\n",
    "        funcs = funcs[:, maxidx]\n",
    "\n",
    "    elif mode == \"maxnorm\":  # pick PSF/CTF with maximum norm\n",
    "        norms = np.linalg.norm(funcs, axis=0)\n",
    "        if n_comp > 1:  # only keep requested number of sorted PSFs/CTFs\n",
    "            sortidx = np.argsort(norms)\n",
    "            maxidx = sortidx[-n_comp:]\n",
    "        else:  # faster if only one required\n",
    "            maxidx = [norms.argmax()]\n",
    "        funcs = funcs[:, maxidx]\n",
    "\n",
    "    elif mode == \"sum\":  # sum across PSFs/CTFs\n",
    "        funcs = np.sum(funcs, axis=1, keepdims=True)\n",
    "\n",
    "    elif mode == \"mean\":  # mean of PSFs/CTFs\n",
    "        funcs = np.mean(funcs, axis=1, keepdims=True)\n",
    "\n",
    "    elif mode == \"pca\":  # SVD across PSFs/CTFs\n",
    "        # compute SVD of PSFs/CTFs across vertices\n",
    "        u, s, _ = np.linalg.svd(funcs, full_matrices=False, compute_uv=True)\n",
    "        if n_comp > 1:\n",
    "            funcs = u[:, :n_comp]\n",
    "        else:\n",
    "            funcs = u[:, 0, np.newaxis]\n",
    "        # if explained variances for SVD components requested\n",
    "        if return_pca_vars:\n",
    "            # explained variance of individual SVD components\n",
    "            s2 = s * s\n",
    "            s_var = 100 * s2[:n_comp] / s2.sum()\n",
    "\n",
    "    return funcs, s_var\n",
    "\n",
    "\n",
    "@verbose\n",
    "def get_point_spread(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    mode=None,\n",
    "    *,\n",
    "    n_comp=1,\n",
    "    norm=False,\n",
    "    return_pca_vars=False,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get point-spread (PSFs) functions for vertices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resmat : array, shape (n_dipoles, n_dipoles)\n",
    "        Forward Operator.\n",
    "    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n",
    "        Source space used to compute resolution matrix.\n",
    "        Must be an InverseOperator if ``vector=True`` and a surface\n",
    "        source space is used.\n",
    "    %(idx_pctf)s\n",
    "    %(mode_pctf)s\n",
    "    %(n_comp_pctf_n)s\n",
    "    %(norm_pctf)s\n",
    "    %(return_pca_vars_pctf)s\n",
    "    %(vector_pctf)s\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    %(stcs_pctf)s\n",
    "    %(pca_vars_pctf)s\n",
    "    \"\"\"  # noqa: E501\n",
    "    return _get_psf_ctf(\n",
    "        resmat,\n",
    "        src,\n",
    "        idx,\n",
    "        func=\"psf\",\n",
    "        mode=mode,\n",
    "        n_comp=n_comp,\n",
    "        norm=norm,\n",
    "        return_pca_vars=return_pca_vars,\n",
    "        vector=vector,\n",
    "    )\n",
    "\n",
    "\n",
    "@verbose\n",
    "def get_cross_talk(\n",
    "    resmat,\n",
    "    src,\n",
    "    idx,\n",
    "    mode=None,\n",
    "    *,\n",
    "    n_comp=1,\n",
    "    norm=False,\n",
    "    return_pca_vars=False,\n",
    "    vector=False,\n",
    "    verbose=None\n",
    "):\n",
    "    \"\"\"Get cross-talk (CTFs) function for vertices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resmat : array, shape (n_dipoles, n_dipoles)\n",
    "        Forward Operator.\n",
    "    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n",
    "        Source space used to compute resolution matrix.\n",
    "        Must be an InverseOperator if ``vector=True`` and a surface\n",
    "        source space is used.\n",
    "    %(idx_pctf)s\n",
    "    %(mode_pctf)s\n",
    "    %(n_comp_pctf_n)s\n",
    "    %(norm_pctf)s\n",
    "    %(return_pca_vars_pctf)s\n",
    "    %(vector_pctf)s\n",
    "    %(verbose)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    %(stcs_pctf)s\n",
    "    %(pca_vars_pctf)s\n",
    "    \"\"\"  # noqa: E501\n",
    "    return _get_psf_ctf(\n",
    "        resmat,\n",
    "        src,\n",
    "        idx,\n",
    "        func=\"ctf\",\n",
    "        mode=mode,\n",
    "        n_comp=n_comp,\n",
    "        norm=norm,\n",
    "        return_pca_vars=return_pca_vars,\n",
    "        vector=vector,\n",
    "    )\n",
    "\n",
    "\n",
    "def _convert_forward_match_inv(fwd, inv):\n",
    "    \"\"\"Ensure forward and inverse operators match.\n",
    "\n",
    "    Inverse operator and forward operator must have same surface orientations,\n",
    "    but can have different source orientation constraints.\n",
    "    \"\"\"\n",
    "    _validate_type(fwd, Forward, \"fwd\")\n",
    "    _validate_type(inv, InverseOperator, \"inverse_operator\")\n",
    "    # did inverse operator use fixed orientation?\n",
    "    is_fixed_inv = _check_fixed_ori(inv)\n",
    "    # did forward operator use fixed orientation?\n",
    "    is_fixed_fwd = _check_fixed_ori(fwd)\n",
    "\n",
    "    # if inv or fwd fixed: do nothing\n",
    "    # if inv loose: surf_ori must be True\n",
    "    # if inv free: surf_ori must be False\n",
    "    if not is_fixed_inv and not is_fixed_fwd:\n",
    "        inv_surf_ori = inv._is_surf_ori\n",
    "        if inv_surf_ori != fwd[\"surf_ori\"]:\n",
    "            fwd = convert_forward_solution(\n",
    "                fwd, surf_ori=inv_surf_ori, force_fixed=False\n",
    "            )\n",
    "\n",
    "    return fwd\n",
    "\n",
    "\n",
    "def _prepare_info(inverse_operator):\n",
    "    \"\"\"Get a usable dict.\"\"\"\n",
    "    # in order to convert sub-leadfield matrix to evoked data type (pretending\n",
    "    # it's an epoch, see in loop below), uses 'info' from inverse solution\n",
    "    # because this has all the correct projector information\n",
    "    info = deepcopy(inverse_operator[\"info\"])\n",
    "    with info._unlock():\n",
    "        info[\"sfreq\"] = 1000.0  # necessary\n",
    "        info[\"projs\"] = inverse_operator[\"projs\"]\n",
    "        info[\"custom_ref_applied\"] = False\n",
    "    return info\n",
    "\n",
    "\n",
    "def _get_matrix_from_inverse_operator(\n",
    "    inverse_operator, forward, method=\"dSPM\", lambda2=1.0 / 9.0\n",
    "):\n",
    "    \"\"\"Get inverse matrix from an inverse operator.\n",
    "\n",
    "    Currently works only for fixed/loose orientation constraints\n",
    "    For loose orientation constraint, the CTFs are computed for the normal\n",
    "    component (pick_ori='normal').\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inverse_operator : instance of InverseOperator\n",
    "        The inverse operator.\n",
    "    forward : instance of Forward\n",
    "        The forward operator.\n",
    "    method : 'MNE' | 'dSPM' | 'sLORETA'\n",
    "        Inverse methods (for apply_inverse).\n",
    "    lambda2 : float\n",
    "        The regularization parameter (for apply_inverse).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    invmat : array, shape (n_dipoles, n_channels)\n",
    "        Inverse matrix associated with inverse operator and specified\n",
    "        parameters.\n",
    "    \"\"\"\n",
    "    # make sure forward and inverse operators match with respect to\n",
    "    # surface orientation\n",
    "    _convert_forward_match_inv(forward, inverse_operator)\n",
    "\n",
    "    info_inv = _prepare_info(inverse_operator)\n",
    "\n",
    "    # only use channels that are good for inverse operator and forward sol\n",
    "    ch_names_inv = info_inv[\"ch_names\"]\n",
    "    n_chs_inv = len(ch_names_inv)\n",
    "    bads_inv = inverse_operator[\"info\"][\"bads\"]\n",
    "\n",
    "    # indices of bad channels\n",
    "    ch_idx_bads = [ch_names_inv.index(ch) for ch in bads_inv]\n",
    "\n",
    "    # create identity matrix as input for inverse operator\n",
    "    # set elements to zero for non-selected channels\n",
    "    id_mat = np.eye(n_chs_inv)\n",
    "\n",
    "    # convert identity matrix to evoked data type (pretending it's an epoch)\n",
    "    ev_id = EvokedArray(id_mat, info=info_inv, tmin=0.0)\n",
    "\n",
    "    # apply inverse operator to identity matrix in order to get inverse matrix\n",
    "    # free orientation constraint not possible because apply_inverse would\n",
    "    # combine components\n",
    "\n",
    "    # check if inverse operator uses fixed source orientations\n",
    "    is_fixed_inv = _check_fixed_ori(inverse_operator)\n",
    "\n",
    "    # choose pick_ori according to inverse operator\n",
    "    if is_fixed_inv:\n",
    "        pick_ori = None\n",
    "    else:\n",
    "        pick_ori = \"vector\"\n",
    "\n",
    "    # columns for bad channels will be zero\n",
    "    invmat_op = apply_inverse(\n",
    "        ev_id, inverse_operator, lambda2=lambda2, method=method, pick_ori=pick_ori\n",
    "    )\n",
    "\n",
    "    # turn source estimate into numpy array\n",
    "    invmat = invmat_op.data\n",
    "\n",
    "    # remove columns for bad channels\n",
    "    # take into account it may be 3D array\n",
    "    invmat = np.delete(invmat, ch_idx_bads, axis=invmat.ndim - 1)\n",
    "\n",
    "    # if 3D array, i.e. multiple values per location (fixed and loose),\n",
    "    # reshape into 2D array\n",
    "    if invmat.ndim == 3:\n",
    "        v0o1 = invmat[0, 1].copy()\n",
    "        v3o2 = invmat[3, 2].copy()\n",
    "        shape = invmat.shape\n",
    "        invmat = invmat.reshape(shape[0] * shape[1], shape[2])\n",
    "        # make sure that reshaping worked\n",
    "        assert np.array_equal(v0o1, invmat[1])\n",
    "        assert np.array_equal(v3o2, invmat[11])\n",
    "\n",
    "    logger.info(\"Dimension of Inverse Matrix: %s\" % str(invmat.shape))\n",
    "\n",
    "    return invmat\n",
    "\n",
    "\n",
    "def _check_fixed_ori(inst):\n",
    "    \"\"\"Check if inverse or forward was computed for fixed orientations.\"\"\"\n",
    "    is_fixed = inst[\"source_ori\"] != FIFF.FIFFV_MNE_FREE_ORI\n",
    "    return is_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 8)\n",
      "    Created the whitener using a noise covariance matrix with rank 298 (8 small eigenvalues omitted)\n",
      "Applying inverse operator to \"\"...\n",
      "    Picked 306 channels from the data\n",
      "    Computing inverse...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Eigenleads need to be weighted ...\n",
      "    Computing residual...\n",
      "    Explained  42.2% variance\n",
      "[done]\n",
      "Dimension of Inverse Matrix: (5124, 306)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5124, 306)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invmat=_get_matrix_from_inverse_operator(inv,fwd,method='MNE',lambda2=1.0/9.0)\n",
    "np.shape(invmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.58385561e-02,  1.25035676e+00,  3.94006737e+02, ...,\n",
       "        -1.17161218e+00, -5.28714932e-01,  3.28696240e+01],\n",
       "       [ 1.41816092e+00, -1.22591786e+00,  2.39017664e-01, ...,\n",
       "         7.17431739e-01,  1.33136299e-01,  8.12469560e+01],\n",
       "       [ 8.49178151e-01, -7.56228682e-01,  3.03595059e+01, ...,\n",
       "        -2.79674982e-01, -9.51984057e-02,  2.57727409e+00],\n",
       "       ...,\n",
       "       [ 1.10887775e+01, -1.21149561e+01,  3.38444265e+02, ...,\n",
       "        -2.53258298e+01,  1.33636466e+01, -7.42201568e+02],\n",
       "       [-7.68319705e+00,  7.22412797e+00, -1.33700372e+02, ...,\n",
       "         1.33897056e+01, -1.16405850e+01, -4.58125344e+02],\n",
       "       [-1.27342119e+01,  1.04908718e+01, -3.57670986e+02, ...,\n",
       "         8.35946210e+00, -1.41821893e+01,  1.02898035e+03]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdf5storage import loadmat, savemat \n",
    "outdict=dict()\n",
    "outdict['invmat']=invmat\n",
    "savemat('invmat',outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.49350252e-03, -1.23003400e-02,  5.59301854e-03, ...,\n",
       "         0.00000000e+00, -8.73633235e-01,  0.00000000e+00],\n",
       "       [-6.21129836e-04,  3.09417118e-04, -1.16783080e-03, ...,\n",
       "         1.43262898e-02, -8.01764796e-03,  1.11057265e-01],\n",
       "       [-9.50026729e-03,  2.96816687e-03, -1.05772831e-02, ...,\n",
       "        -1.25216461e-01, -3.37660921e-03,  6.96476985e-02],\n",
       "       ...,\n",
       "       [ 1.34332279e-02, -2.35726852e-03,  1.98116475e-03, ...,\n",
       "        -7.12540034e-04, -3.25442047e-05,  1.42946253e-03],\n",
       "       [-9.95980762e-03,  2.16699934e-03,  6.08271509e-04, ...,\n",
       "        -8.04086621e-03, -4.34916917e-03,  3.93421716e-03],\n",
       "       [-2.05030411e-02,  2.50521413e-03, -1.34182275e-03, ...,\n",
       "         1.64534134e-03,  1.26466811e-03,  1.69529560e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv['eigen_leads']['data']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
